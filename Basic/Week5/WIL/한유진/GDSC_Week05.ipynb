{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pprint import pprint\n",
        "%matplotlib inline\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErYTYjSJGLld",
        "outputId": "a9657d2c-16c1-4c00-9114-b1cbdaa80807"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 12-0 RNN basics"
      ],
      "metadata": {
        "id": "H657dQFbGL2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing dataset"
      ],
      "metadata": {
        "id": "CietJVYZGVen"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "soX7MKKuFSru"
      },
      "outputs": [],
      "source": [
        "# One hot encoding for each char in 'hello'\n",
        "h = [1, 0, 0, 0]\n",
        "e = [0, 1, 0, 0]\n",
        "l = [0, 0, 1, 0]\n",
        "o = [0, 0, 0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One cell RNN input_dim (4) -> output_dim (2)\n",
        "x_data = np.array([[h]], dtype=np.float32)\n",
        "\n",
        "hidden_size = 2\n",
        "cell = layers.SimpleRNNCell(units=hidden_size)\n",
        "rnn = layers.RNN(cell, return_sequences=True, return_state=True)\n",
        "outputs, states = rnn(x_data)\n",
        "\n",
        "print('x_data: {}, shape: {}'.format(x_data, x_data.shape))\n",
        "print('outputs: {}, shape: {}'.format(outputs, outputs.shape))\n",
        "print('states: {}, shape: {}'.format(states, states.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsnlSw3MGeMs",
        "outputId": "6bcfc8de-84f8-4509-b952-969d524060e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data: [[[1. 0. 0. 0.]]], shape: (1, 1, 4)\n",
            "outputs: [[[ 0.6220399  -0.45636514]]], shape: (1, 1, 2)\n",
            "states: [[ 0.6220399  -0.45636514]], shape: (1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# equivalent to above case\n",
        "rnn = layers.SimpleRNN(units=hidden_size, return_sequences=True,\n",
        "                       return_state=True) # layers.SimpleRNNCell + layers.RNN\n",
        "\n",
        "outputs, states = rnn(x_data)\n",
        "\n",
        "print('x_data: {}, shape: {}'.format(x_data, x_data.shape))\n",
        "print('outputs: {}, shape: {}'.format(outputs, outputs.shape))\n",
        "print('states: {}, shape: {}'.format(states, states.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3JBLmvcGjb7",
        "outputId": "efa88609-3df9-4390-a1ab-36f6b4d6332c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data: [[[1. 0. 0. 0.]]], shape: (1, 1, 4)\n",
            "outputs: [[[0.16564184 0.4271997 ]]], shape: (1, 1, 2)\n",
            "states: [[0.16564184 0.4271997 ]], shape: (1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unfolding to n sequences"
      ],
      "metadata": {
        "id": "akp2wYPpHGYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
        "x_data = np.array([[h, e, l, l, o]], dtype=np.float32)\n",
        "\n",
        "hidden_size = 2\n",
        "rnn = layers.SimpleRNN(units=2, return_sequences=True, return_state=True)\n",
        "outputs, states = rnn(x_data)\n",
        "\n",
        "print('x_data: {}, shape: {} \\n'.format(x_data, x_data.shape))\n",
        "print('outputs: {}, shape: {} \\n'.format(outputs, outputs.shape))\n",
        "print('states: {}, shape: {}'.format(states, states.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztSgFuEYHJCn",
        "outputId": "636d8521-da19-41be-e4d5-c0b9c7c34ae4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data: [[[1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1.]]], shape: (1, 5, 4) \n",
            "\n",
            "outputs: [[[ 0.20401761  0.4798481 ]\n",
            "  [-0.3352268  -0.8539934 ]\n",
            "  [-0.56979984  0.90769285]\n",
            "  [ 0.37455532  0.07364048]\n",
            "  [ 0.5283787   0.27479172]]], shape: (1, 5, 2) \n",
            "\n",
            "states: [[0.5283787  0.27479172]], shape: (1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batching input"
      ],
      "metadata": {
        "id": "1Jx2q5z3Hgtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
        "x_data = np.array([[h, e, l, l, o],\n",
        "                   [e, o, l, l, l],\n",
        "                   [l, l, e, e, l]], dtype=np.float32)\n",
        "\n",
        "hidden_size = 2\n",
        "rnn = layers.SimpleRNN(units=2, return_sequences=True, return_state=True)\n",
        "outputs, states = rnn(x_data)\n",
        "\n",
        "print('x_data: {}, shape: {} \\n'.format(x_data, x_data.shape))\n",
        "print('outputs: {}, shape: {} \\n'.format(outputs, outputs.shape))\n",
        "print('states: {}, shape: {}'.format(states, states.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYLnipNhHY68",
        "outputId": "a2f20aba-a9b0-4390-8c62-0ff1bc1df273"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data: [[[1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1.]]\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]]\n",
            "\n",
            " [[0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0.]]], shape: (3, 5, 4) \n",
            "\n",
            "outputs: [[[ 0.5512991   0.40168622]\n",
            "  [ 0.79069376  0.41693395]\n",
            "  [ 0.5670397  -0.6739208 ]\n",
            "  [ 0.12559107 -0.9472396 ]\n",
            "  [ 0.6299098  -0.87202823]]\n",
            "\n",
            " [[ 0.40726516  0.20754153]\n",
            "  [ 0.86964154 -0.30026084]\n",
            "  [ 0.47806492 -0.91023844]\n",
            "  [-0.02465386 -0.96449465]\n",
            "  [-0.4798205  -0.95788634]]\n",
            "\n",
            " [[-0.22798507 -0.76144594]\n",
            "  [-0.57964426 -0.9313164 ]\n",
            "  [-0.3648563  -0.48067278]\n",
            "  [-0.05128737 -0.14916405]\n",
            "  [-0.31189084 -0.8106027 ]]], shape: (3, 5, 2) \n",
            "\n",
            "states: [[ 0.6299098  -0.87202823]\n",
            " [-0.4798205  -0.95788634]\n",
            " [-0.31189084 -0.8106027 ]], shape: (3, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 12-1 Many to One"
      ],
      "metadata": {
        "id": "zC6JvdxrHm4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing dataset"
      ],
      "metadata": {
        "id": "PEdmF4YpH0Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example data\n",
        "words = ['good', 'bad', 'worse', 'so good']\n",
        "y_data = [1,0,0,1]\n",
        "\n",
        "# creating a token dictionary\n",
        "char_set = ['<pad>'] + sorted(list(set(''.join(words))))\n",
        "idx2char = {idx : char for idx, char in enumerate(char_set)}\n",
        "char2idx = {char : idx for idx, char in enumerate(char_set)}\n",
        "\n",
        "print(char_set)\n",
        "print(idx2char)\n",
        "print(char2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtiASYWJHyM_",
        "outputId": "b800bb85-a611-4bdb-89a4-c49dc42f7517"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>', ' ', 'a', 'b', 'd', 'e', 'g', 'o', 'r', 's', 'w']\n",
            "{0: '<pad>', 1: ' ', 2: 'a', 3: 'b', 4: 'd', 5: 'e', 6: 'g', 7: 'o', 8: 'r', 9: 's', 10: 'w'}\n",
            "{'<pad>': 0, ' ': 1, 'a': 2, 'b': 3, 'd': 4, 'e': 5, 'g': 6, 'o': 7, 'r': 8, 's': 9, 'w': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting sequence of tokens to sequence of indices\n",
        "x_data = list(map(lambda word : [char2idx.get(char) for char in word], words))\n",
        "x_data_len = list(map(lambda word : len(word), x_data))\n",
        "\n",
        "print(x_data)\n",
        "print(x_data_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8DGYFe0Hmcy",
        "outputId": "9a2bcf50-9b31-4975-c484-a226ed2a66ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6, 7, 7, 4], [3, 2, 4], [10, 7, 8, 9, 5], [9, 7, 1, 6, 7, 7, 4]]\n",
            "[4, 3, 5, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding the sequence of indices\n",
        "max_sequence = 10\n",
        "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence, padding = 'post', truncating = 'post')\n",
        "\n",
        "print(x_data)\n",
        "print(x_data_len)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vplb9o8TH3-i",
        "outputId": "25b5c95e-b6ce-4c00-998b-7a9b17731520"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6  7  7  4  0  0  0  0  0  0]\n",
            " [ 3  2  4  0  0  0  0  0  0  0]\n",
            " [10  7  8  9  5  0  0  0  0  0]\n",
            " [ 9  7  1  6  7  7  4  0  0  0]]\n",
            "[4, 3, 5, 7]\n",
            "[1, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model"
      ],
      "metadata": {
        "id": "QicETuVBH8or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating simple rnn for \"many to one\" classification\n",
        "input_dim = len(char2idx)\n",
        "output_dim = len(char2idx)\n",
        "one_hot = np.eye(len(char2idx))\n",
        "hidden_size = 10\n",
        "num_classes = 2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
        "                           trainable=False, mask_zero=True, input_length=max_sequence,\n",
        "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
        "model.add(layers.SimpleRNN(units=hidden_size))\n",
        "model.add(layers.Dense(units=num_classes))"
      ],
      "metadata": {
        "id": "he9PDlIaIAch"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn7T689EICrH",
        "outputId": "58941f66-a8d2-4c65-e516-e19106eb9d01"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 11)            121       \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 10)                220       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 363 (1.42 KB)\n",
            "Trainable params: 242 (968.00 Byte)\n",
            "Non-trainable params: 121 (484.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training model"
      ],
      "metadata": {
        "id": "EAJOAG6MIEfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating loss function\n",
        "def loss_fn(model, x, y):\n",
        "    return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x), from_logits=True))\n",
        "\n",
        "# creating an optimizer\n",
        "lr = .01\n",
        "epochs = 30\n",
        "batch_size = 2\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
      ],
      "metadata": {
        "id": "XxQwE-o2IGrj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating data pipeline\n",
        "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
        "tr_dataset = tr_dataset.shuffle(buffer_size = 4)\n",
        "tr_dataset = tr_dataset.batch(batch_size = batch_size)\n",
        "\n",
        "print(tr_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87PWWRU9IKMi",
        "outputId": "d59e2122-43d2-4901-a9c1-d9106e26514b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "tr_loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "\n",
        "    for x_mb, y_mb in tr_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x=x_mb, y=y_mb)\n",
        "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
        "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    else:\n",
        "        avg_tr_loss /= tr_step\n",
        "        tr_loss_hist.append(avg_tr_loss)\n",
        "\n",
        "    if (epoch + 1) % 5 ==0:\n",
        "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avQ5qIBKIK2j",
        "outputId": "1ca84eee-e62a-4ab3-d461-146aadb7adae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :   5, tr_loss : 0.229\n",
            "epoch :  10, tr_loss : 0.049\n",
            "epoch :  15, tr_loss : 0.017\n",
            "epoch :  20, tr_loss : 0.009\n",
            "epoch :  25, tr_loss : 0.006\n",
            "epoch :  30, tr_loss : 0.005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking performance"
      ],
      "metadata": {
        "id": "6FNp869eINOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(x_data)\n",
        "yhat = np.argmax(yhat, axis=-1)\n",
        "print('acc : {:.2%}'.format(np.mean(yhat == y_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L8nAEfsIPdB",
        "outputId": "87d6a9a9-2505-4ca1-e8b6-25f284b8bec0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 200ms/step\n",
            "acc : 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tr_loss_hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ZJVjaSXvIRER",
        "outputId": "851746a3-2565-4693-d13e-6cd61c73d192"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7d14dd24b730>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 12-2 Many to One Stacking"
      ],
      "metadata": {
        "id": "Hvw5iQYIIuJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing dataset"
      ],
      "metadata": {
        "id": "ALdQ1GmRI-cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example data\n",
        "sentences = ['What I cannot create, I do not understand.',\n",
        "             'Intellecuals solve problems, geniuses prevent them',\n",
        "             'A person who never made a mistake never tied anything new.',\n",
        "             'The same equations have the same solutions.']\n",
        "y_data = [1,0,0,1]"
      ],
      "metadata": {
        "id": "8Acz5TEXIx4d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a token dictionary\n",
        "char_set = ['<pad>'] + sorted(list(set(''.join(sentences))))\n",
        "idx2char = {idx : char for idx, char in enumerate(char_set)}\n",
        "char2idx = {char : idx for idx, char in enumerate(char_set)}\n",
        "\n",
        "print(char_set)\n",
        "print(idx2char)\n",
        "print(char2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai42dTkAJDKN",
        "outputId": "d2973084-addd-4d4b-fcdd-2fad86561d49"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>', ' ', ',', '.', 'A', 'I', 'T', 'W', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
            "{0: '<pad>', 1: ' ', 2: ',', 3: '.', 4: 'A', 5: 'I', 6: 'T', 7: 'W', 8: 'a', 9: 'b', 10: 'c', 11: 'd', 12: 'e', 13: 'g', 14: 'h', 15: 'i', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'y'}\n",
            "{'<pad>': 0, ' ': 1, ',': 2, '.': 3, 'A': 4, 'I': 5, 'T': 6, 'W': 7, 'a': 8, 'b': 9, 'c': 10, 'd': 11, 'e': 12, 'g': 13, 'h': 14, 'i': 15, 'k': 16, 'l': 17, 'm': 18, 'n': 19, 'o': 20, 'p': 21, 'q': 22, 'r': 23, 's': 24, 't': 25, 'u': 26, 'v': 27, 'w': 28, 'y': 29}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting sequence of tokens to sequence of indices\n",
        "x_data = list(map(lambda sentence : [char2idx.get(char) for char in sentence], sentences))\n",
        "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
        "\n",
        "print(x_data)\n",
        "print(x_data_len)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwlI2b8fJEHB",
        "outputId": "2f07d871-cdec-48bf-d5f0-63fcde69726c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7, 14, 8, 25, 1, 5, 1, 10, 8, 19, 19, 20, 25, 1, 10, 23, 12, 8, 25, 12, 2, 1, 5, 1, 11, 20, 1, 19, 20, 25, 1, 26, 19, 11, 12, 23, 24, 25, 8, 19, 11, 3], [5, 19, 25, 12, 17, 17, 12, 10, 26, 8, 17, 24, 1, 24, 20, 17, 27, 12, 1, 21, 23, 20, 9, 17, 12, 18, 24, 2, 1, 13, 12, 19, 15, 26, 24, 12, 24, 1, 21, 23, 12, 27, 12, 19, 25, 1, 25, 14, 12, 18], [4, 1, 21, 12, 23, 24, 20, 19, 1, 28, 14, 20, 1, 19, 12, 27, 12, 23, 1, 18, 8, 11, 12, 1, 8, 1, 18, 15, 24, 25, 8, 16, 12, 1, 19, 12, 27, 12, 23, 1, 25, 15, 12, 11, 1, 8, 19, 29, 25, 14, 15, 19, 13, 1, 19, 12, 28, 3], [6, 14, 12, 1, 24, 8, 18, 12, 1, 12, 22, 26, 8, 25, 15, 20, 19, 24, 1, 14, 8, 27, 12, 1, 25, 14, 12, 1, 24, 8, 18, 12, 1, 24, 20, 17, 26, 25, 15, 20, 19, 24, 3]]\n",
            "[42, 50, 58, 43]\n",
            "[1, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding the sequence of indices\n",
        "max_sequence = 55\n",
        "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence,\n",
        "                       padding = 'post', truncating = 'post')\n",
        "\n",
        "# checking data\n",
        "print(x_data)\n",
        "print(x_data_len)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57o_sOAvJFP3",
        "outputId": "80508783-97ef-49e9-c58e-62137399baa2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 14  8 25  1  5  1 10  8 19 19 20 25  1 10 23 12  8 25 12  2  1  5  1\n",
            "  11 20  1 19 20 25  1 26 19 11 12 23 24 25  8 19 11  3  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]\n",
            " [ 5 19 25 12 17 17 12 10 26  8 17 24  1 24 20 17 27 12  1 21 23 20  9 17\n",
            "  12 18 24  2  1 13 12 19 15 26 24 12 24  1 21 23 12 27 12 19 25  1 25 14\n",
            "  12 18  0  0  0  0  0]\n",
            " [ 4  1 21 12 23 24 20 19  1 28 14 20  1 19 12 27 12 23  1 18  8 11 12  1\n",
            "   8  1 18 15 24 25  8 16 12  1 19 12 27 12 23  1 25 15 12 11  1  8 19 29\n",
            "  25 14 15 19 13  1 19]\n",
            " [ 6 14 12  1 24  8 18 12  1 12 22 26  8 25 15 20 19 24  1 14  8 27 12  1\n",
            "  25 14 12  1 24  8 18 12  1 24 20 17 26 25 15 20 19 24  3  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0]]\n",
            "[42, 50, 58, 43]\n",
            "[1, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model"
      ],
      "metadata": {
        "id": "T2_AIBeBJGCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating stacked rnn for \"many to one\" classification with dropout\n",
        "num_classes = 2\n",
        "hidden_dims = [10,10]\n",
        "\n",
        "input_dim = len(char2idx)\n",
        "output_dim = len(char2idx)\n",
        "one_hot = np.eye(len(char2idx))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
        "                           trainable=False, mask_zero=True, input_length=max_sequence,\n",
        "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
        "model.add(layers.SimpleRNN(units=hidden_dims[0], return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dropout(rate = .2)))\n",
        "model.add(layers.SimpleRNN(units=hidden_dims[1]))\n",
        "model.add(layers.Dropout(rate = .2))\n",
        "model.add(layers.Dense(units=num_classes))"
      ],
      "metadata": {
        "id": "K4v5j7NFJH2h"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i3pY2m5JJzm",
        "outputId": "d4a5b338-428e-4581-816e-af690da589cc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 55, 30)            900       \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 55, 10)            410       \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 55, 10)            0         \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " simple_rnn_5 (SimpleRNN)    (None, 10)                210       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1542 (6.02 KB)\n",
            "Trainable params: 642 (2.51 KB)\n",
            "Non-trainable params: 900 (3.52 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training model"
      ],
      "metadata": {
        "id": "VNsX4C3aJTHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating loss function\n",
        "def loss_fn(model, x, y, training):\n",
        "    return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x, training), from_logits=True))\n",
        "\n",
        "# creating and optimizer\n",
        "lr = .01\n",
        "epochs = 30\n",
        "batch_size = 2\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
      ],
      "metadata": {
        "id": "PYqU2WR0JUcy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating data pipeline\n",
        "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
        "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
        "tr_dataset = tr_dataset.batch(batch_size=batch_size)\n",
        "\n",
        "print(tr_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR9WAQUcJWOD",
        "outputId": "2056ccfa-bb51-402f-9638-846e7cac1f80"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(None, 55), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "tr_loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "\n",
        "    for x_mb, y_mb in tr_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, training=True)\n",
        "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
        "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    else:\n",
        "        avg_tr_loss /= tr_step\n",
        "        tr_loss_hist.append(avg_tr_loss)\n",
        "\n",
        "    if (epoch + 1) % 5 ==0:\n",
        "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaJPI0NuJYi4",
        "outputId": "35d56cea-cf59-4990-bfd9-d08de8a87632"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :   5, tr_loss : 0.411\n",
            "epoch :  10, tr_loss : 0.099\n",
            "epoch :  15, tr_loss : 0.035\n",
            "epoch :  20, tr_loss : 0.096\n",
            "epoch :  25, tr_loss : 0.004\n",
            "epoch :  30, tr_loss : 0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking performance"
      ],
      "metadata": {
        "id": "DFCqePC6JcQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(x_data)\n",
        "yhat = np.argmax(yhat, axis=-1)\n",
        "print('accuracy : {:.2%}'.format(np.mean(yhat == y_data)))"
      ],
      "metadata": {
        "id": "KraYT6zuJehk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tr_loss_hist)"
      ],
      "metadata": {
        "id": "lMIIyO5nJgNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 12-3 Many to Many"
      ],
      "metadata": {
        "id": "KZUtkzyqJhk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepairing dataset"
      ],
      "metadata": {
        "id": "Dr1FRQVuJoZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example data\n",
        "sentences = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "pos = [['pronoun', 'verb', 'adjective'],\n",
        "     ['noun', 'verb', 'adverb', 'adjective'],\n",
        "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
        "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
      ],
      "metadata": {
        "id": "7UHJE7gVJnct"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing dataset"
      ],
      "metadata": {
        "id": "c5N8orpiJtYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a token dictionary for word\n",
        "word_list = sum(sentences, [])\n",
        "word_list = sorted(set(word_list))\n",
        "word_list = ['<pad>'] + word_list\n",
        "word2idx = {word : idx for idx, word in enumerate(word_list)}\n",
        "idx2word = {idx : word for idx, word in enumerate(word_list)}\n",
        "\n",
        "print(word2idx)\n",
        "print(idx2word)\n",
        "print(len(idx2word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPK_iZqoJtCn",
        "outputId": "e692e62c-c919-48c8-fd9b-1a1bad43a01d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
            "{0: '<pad>', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a token dictionary for part of speech\n",
        "pos_list = sum(pos, [])\n",
        "pos_list = sorted(set(pos_list))\n",
        "pos_list = ['<pad>'] + pos_list\n",
        "pos2idx = {pos : idx for idx, pos in enumerate(pos_list)}\n",
        "idx2pos = {idx : pos for idx, pos in enumerate(pos_list)}\n",
        "\n",
        "print(pos2idx)\n",
        "print(idx2pos)\n",
        "print(len(pos2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrCb-tO0JxtF",
        "outputId": "c7fa954d-1220-4534-912a-5fc2c24ce867"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
            "{0: '<pad>', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting sequence of tokens to sequence of indices\n",
        "max_sequence = 10\n",
        "x_data = list(map(lambda sentence : [word2idx.get(token) for token in sentence], sentences))\n",
        "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
        "\n",
        "# padding the sequence of indices\n",
        "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence, padding='post')\n",
        "x_data_mask = ((x_data != 0) * 1).astype(np.float32)\n",
        "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
        "\n",
        "y_data = pad_sequences(sequences = y_data, maxlen = max_sequence, padding='post')\n",
        "\n",
        "print(x_data, x_data_len)\n",
        "print(x_data_mask)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfhPQhxKJyuF",
        "outputId": "21b4165d-3a3a-4c66-c4b1-f0933a9a1b90"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
            "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "[[6 7 1 0 0 0 0 0 0 0]\n",
            " [4 7 2 1 0 0 0 0 0 0]\n",
            " [4 7 3 4 5 1 4 0 0 0]\n",
            " [4 7 2 1 7 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model"
      ],
      "metadata": {
        "id": "JUB1RGs4J0wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating rnn for \"many to many\" sequence tagging\n",
        "num_classes = len(pos2idx)\n",
        "hidden_dim = 10\n",
        "\n",
        "input_dim = len(word2idx)\n",
        "output_dim = len(word2idx)\n",
        "one_hot = np.eye(len(word2idx))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True, trainable=False, input_length=max_sequence, embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
        "model.add(layers.SimpleRNN(units=hidden_dim, return_sequences=True))\n",
        "model.add(layers.TimeDistributed(layers.Dense(units=num_classes)))"
      ],
      "metadata": {
        "id": "nHnUzuFsJ2Q8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwmI5qRyJ30u",
        "outputId": "c63423fd-f519-4d7c-b090-f1bfa9510930"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 10, 15)            225       \n",
            "                                                                 \n",
            " simple_rnn_6 (SimpleRNN)    (None, 10, 10)            260       \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDi  (None, 10, 8)             88        \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 573 (2.24 KB)\n",
            "Trainable params: 348 (1.36 KB)\n",
            "Non-trainable params: 225 (900.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training model"
      ],
      "metadata": {
        "id": "PXmr1fo1J--E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating loss function\n",
        "def loss_fn(model, x, y, x_len, max_sequence):\n",
        "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
        "    valid_time_step = tf.cast(x_len,dtype=tf.float32)\n",
        "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x), from_logits=True) * masking\n",
        "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step\n",
        "    sequence_loss = tf.reduce_mean(sequence_loss)\n",
        "    return sequence_loss\n",
        "\n",
        "# creating and optimizer\n",
        "lr = 0.1\n",
        "epochs = 30\n",
        "batch_size = 2\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
      ],
      "metadata": {
        "id": "_YQjkTqbKAos"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating data pipeline\n",
        "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len))\n",
        "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
        "tr_dataset = tr_dataset.batch(batch_size = 2)\n",
        "\n",
        "print(tr_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxAikAUsKCew",
        "outputId": "f84f8ffb-fd5c-4aa1-8cca-c120e84f4aa5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "tr_loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "\n",
        "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
        "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
        "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    else:\n",
        "        avg_tr_loss /= tr_step\n",
        "        tr_loss_hist.append(avg_tr_loss)\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQveUZzCKD_C",
        "outputId": "9758fe0f-2b2b-4530-c8cb-746229aa305c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :   5, tr_loss : 0.131\n",
            "epoch :  10, tr_loss : 0.009\n",
            "epoch :  15, tr_loss : 0.002\n",
            "epoch :  20, tr_loss : 0.001\n",
            "epoch :  25, tr_loss : 0.001\n",
            "epoch :  30, tr_loss : 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking performance"
      ],
      "metadata": {
        "id": "8dbsI3YlKF8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(x_data)\n",
        "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
        "\n",
        "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row],yhat.astype(np.int32).tolist())), width = 120)\n",
        "pprint(pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW0Yiw0GKJht",
        "outputId": "ff87f19a-1119-4b7c-a649-fb253e9b2c4a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 186ms/step\n",
            "[['pronoun', 'verb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '<pad>', '<pad>', '<pad>'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
            "[['pronoun', 'verb', 'adjective'],\n",
            " ['noun', 'verb', 'adverb', 'adjective'],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tr_loss_hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "Wrg8dDK6KKeG",
        "outputId": "05650141-a201-4bda-b2a0-8aeffbc790bb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7d14cfcd6c50>]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 12-4 Many to Many Variable Bidirectional"
      ],
      "metadata": {
        "id": "I4d2BjS5KNZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing dataset"
      ],
      "metadata": {
        "id": "SHjN3dvCKdDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example data\n",
        "sentences = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "pos = [['pronoun', 'verb', 'adjective'],\n",
        "     ['noun', 'verb', 'adverb', 'adjective'],\n",
        "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
        "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
      ],
      "metadata": {
        "id": "9OAuPrd1KkNy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing dataset"
      ],
      "metadata": {
        "id": "3LIz2SzSKgDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a token dictionary for word\n",
        "word_list = sum(sentences, [])\n",
        "word_list = sorted(set(word_list))\n",
        "word_list = ['<pad>'] + word_list\n",
        "word2idx = {word : idx for idx, word in enumerate(word_list)}\n",
        "idx2word = {idx : word for idx, word in enumerate(word_list)}\n",
        "\n",
        "print(word2idx)\n",
        "print(idx2word)\n",
        "print(len(idx2word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjfTcqMjKcdE",
        "outputId": "60716433-684f-4899-deb8-1266f0919a80"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
            "{0: '<pad>', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a token dictionary for part of speech\n",
        "pos_list = sum(pos, [])\n",
        "pos_list = sorted(set(pos_list))\n",
        "pos_list = ['<pad>'] + pos_list\n",
        "pos2idx = {pos : idx for idx, pos in enumerate(pos_list)}\n",
        "idx2pos = {idx : pos for idx, pos in enumerate(pos_list)}\n",
        "\n",
        "print(pos2idx)\n",
        "print(idx2pos)\n",
        "print(len(pos2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRH_pyH0KnQT",
        "outputId": "48d39ca1-16eb-4a8d-d93d-1126c953f99c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
            "{0: '<pad>', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting sequence of tokens to sequence of indices\n",
        "max_sequence = 10\n",
        "x_data = list(map(lambda sentence : [word2idx.get(token) for token in sentence], sentences))\n",
        "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
        "\n",
        "# padding the sequence of indices\n",
        "x_data = pad_sequences(sequences = x_data, maxlen = max_sequence, padding='post')\n",
        "x_data_mask = ((x_data != 0) * 1).astype(np.float32)\n",
        "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
        "\n",
        "y_data = pad_sequences(sequences = y_data, maxlen = max_sequence, padding='post')\n",
        "\n",
        "print(x_data, x_data_len)\n",
        "print(x_data_mask)\n",
        "print(y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPQoD5VDKoqh",
        "outputId": "bf04e6fc-f301-45ed-e6df-1d0bfa57b5ec"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
            "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "[[6 7 1 0 0 0 0 0 0 0]\n",
            " [4 7 2 1 0 0 0 0 0 0]\n",
            " [4 7 3 4 5 1 4 0 0 0]\n",
            " [4 7 2 1 7 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model"
      ],
      "metadata": {
        "id": "ewKvG7_cKpsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating bidirectional rnn for \"many to many\" sequence tagging\n",
        "num_classes = len(pos2idx)\n",
        "hidden_dim = 10\n",
        "\n",
        "input_dim = len(word2idx)\n",
        "output_dim = len(word2idx)\n",
        "one_hot = np.eye(len(word2idx))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.InputLayer(input_shape=(max_sequence,)))\n",
        "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True, trainable=False, input_length=max_sequence, embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
        "model.add(layers.Bidirectional(keras.layers.SimpleRNN(units=hidden_dim, return_sequences=True)))\n",
        "model.add(layers.TimeDistributed(keras.layers.Dense(units=num_classes)))"
      ],
      "metadata": {
        "id": "ZxTdXNiqKrDJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccWlAq8pKsj8",
        "outputId": "ecc9c8c5-bf20-44c9-84bc-46efeaab5372"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 10, 15)            225       \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 10, 20)            520       \n",
            " al)                                                             \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDi  (None, 10, 8)             168       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 913 (3.57 KB)\n",
            "Trainable params: 688 (2.69 KB)\n",
            "Non-trainable params: 225 (900.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training model"
      ],
      "metadata": {
        "id": "US-Tjmm-Kyjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating loss function\n",
        "def loss_fn(model, x, y, x_len, max_sequence):\n",
        "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
        "    valid_time_step = tf.cast(x_len,dtype=tf.float32)\n",
        "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y_true=y, y_pred=model(x), from_logits=True) * masking\n",
        "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step\n",
        "    sequence_loss = tf.reduce_mean(sequence_loss)\n",
        "    return sequence_loss\n",
        "\n",
        "# creating and optimizer\n",
        "lr = 0.1\n",
        "epochs = 30\n",
        "batch_size = 2\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
      ],
      "metadata": {
        "id": "pCA_ZwOoKzrz"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generating data pipeline\n",
        "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len))\n",
        "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
        "tr_dataset = tr_dataset.batch(batch_size = 2)\n",
        "\n",
        "print(tr_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clWcdR3BK1qw",
        "outputId": "793b12c4-fe8b-49f3-d138-84be0c7911ef"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "tr_loss_hist = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_tr_loss = 0\n",
        "    tr_step = 0\n",
        "\n",
        "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
        "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
        "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
        "        avg_tr_loss += tr_loss\n",
        "        tr_step += 1\n",
        "    else:\n",
        "        avg_tr_loss /= tr_step\n",
        "        tr_loss_hist.append(avg_tr_loss)\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPdXIfs4K2_O",
        "outputId": "d95f6023-69c0-4961-f9c7-0b7cfb1bc54d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :   5, tr_loss : 0.010\n",
            "epoch :  10, tr_loss : 0.001\n",
            "epoch :  15, tr_loss : 0.000\n",
            "epoch :  20, tr_loss : 0.000\n",
            "epoch :  25, tr_loss : 0.000\n",
            "epoch :  30, tr_loss : 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking performance"
      ],
      "metadata": {
        "id": "jRacR6VGK46W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(x_data)\n",
        "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
        "\n",
        "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row],yhat.astype(np.int32).tolist())), width = 120)\n",
        "pprint(pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab4mfVCGK8co",
        "outputId": "528bc683-9dce-4bb0-f352-8d613a00e1f0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 383ms/step\n",
            "[['pronoun', 'verb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '<pad>', '<pad>', '<pad>'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
            "[['pronoun', 'verb', 'adjective'],\n",
            " ['noun', 'verb', 'adverb', 'adjective'],\n",
            " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
            " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tr_loss_hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "mJkFFFVQK9oG",
        "outputId": "337b7d06-f340-475d-9e07-effd71b3d144"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7d14cfa41330>]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 12-5 Sequence to Sequence"
      ],
      "metadata": {
        "id": "SCKzm2voLB4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import tensorflow as tf\n",
        "from matplotlib import font_manager, rc\n",
        "\n",
        "rc('font', family='AppleGothic') #for mac\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgYrlMrFLKHX",
        "outputId": "cca782ee-dadc-4104-8090-3848f0d5eb59"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sources = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "targets = [['나는', '배가', '고프다'],\n",
        "           ['텐서플로우는', '매우', '어렵다'],\n",
        "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
        "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
      ],
      "metadata": {
        "id": "_5jc0aqiLOeu"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary for sources\n",
        "s_vocab = list(set(sum(sources, [])))\n",
        "s_vocab.sort()\n",
        "s_vocab = ['<pad>'] + s_vocab\n",
        "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
        "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
        "\n",
        "pprint(source2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y75_xftvLPyB",
        "outputId": "22122323-5d2e-40e3-d590-2e12d77319f2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0,\n",
            " 'I': 1,\n",
            " 'a': 2,\n",
            " 'changing': 3,\n",
            " 'deep': 4,\n",
            " 'difficult': 5,\n",
            " 'fast': 6,\n",
            " 'feel': 7,\n",
            " 'for': 8,\n",
            " 'framework': 9,\n",
            " 'hungry': 10,\n",
            " 'is': 11,\n",
            " 'learning': 12,\n",
            " 'tensorflow': 13,\n",
            " 'very': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary for targets\n",
        "t_vocab = list(set(sum(targets, [])))\n",
        "t_vocab.sort()\n",
        "t_vocab = ['<pad>', '<bos>', '<eos>'] + t_vocab\n",
        "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
        "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
        "\n",
        "pprint(target2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "munwH_TTLRGX",
        "outputId": "08646ae7-17dd-4899-9b2a-330995ee67ea"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<bos>': 1,\n",
            " '<eos>': 2,\n",
            " '<pad>': 0,\n",
            " '고프다': 3,\n",
            " '나는': 4,\n",
            " '딥러닝을': 5,\n",
            " '매우': 6,\n",
            " '배가': 7,\n",
            " '변화한다': 8,\n",
            " '빠르게': 9,\n",
            " '어렵다': 10,\n",
            " '위한': 11,\n",
            " '텐서플로우는': 12,\n",
            " '프레임워크이다': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
        "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
        "\n",
        "    if mode == 'source':\n",
        "        # preprocessing for source (encoder)\n",
        "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
        "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
        "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        return s_len, s_input\n",
        "\n",
        "    elif mode == 'target':\n",
        "        # preprocessing for target (decoder)\n",
        "        # input\n",
        "        t_input = list(map(lambda sentence : ['<bos>'] + sentence + ['<eos>'], sequences))\n",
        "        t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
        "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
        "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "\n",
        "        # output\n",
        "        t_output = list(map(lambda sentence : sentence + ['<eos>'], sequences))\n",
        "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
        "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "\n",
        "        return t_len, t_input, t_output"
      ],
      "metadata": {
        "id": "vaxa5NeILTnJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing for source\n",
        "s_max_len = 10\n",
        "s_len, s_input = preprocess(sequences = sources,\n",
        "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
        "print(s_len, s_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqjYJyfiLVXn",
        "outputId": "e6e0b012-e619-45b1-d3dd-8f1917a92d20"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing for target\n",
        "t_max_len = 12\n",
        "t_len, t_input, t_output = preprocess(sequences = targets,\n",
        "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
        "print(t_len, t_input, t_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdYwK_XOLWrg",
        "outputId": "51377e72-1a57-4461-d4e6-791ca6503ddf"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 5, 6, 6] [[ 1  4  7  3  2  0  0  0  0  0  0  0]\n",
            " [ 1 12  6 10  2  0  0  0  0  0  0  0]\n",
            " [ 1 12  5 11 13  2  0  0  0  0  0  0]\n",
            " [ 1 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
            " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
            " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
            " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyper-param"
      ],
      "metadata": {
        "id": "o76DBXx-LX61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters\n",
        "epochs = 200\n",
        "batch_size = 4\n",
        "learning_rate = .005\n",
        "total_step = epochs / batch_size\n",
        "buffer_size = 100\n",
        "n_batch = buffer_size//batch_size\n",
        "embedding_dim = 32\n",
        "units = 32\n",
        "\n",
        "# input\n",
        "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
        "data = data.shuffle(buffer_size = buffer_size)\n",
        "data = data.batch(batch_size = batch_size)"
      ],
      "metadata": {
        "id": "kXeY2u6ALaDA"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gru(units):\n",
        "    return tf.keras.layers.GRU(units,\n",
        "                               return_sequences=True,\n",
        "                               return_state=True,\n",
        "                               recurrent_initializer='glorot_uniform')"
      ],
      "metadata": {
        "id": "ThaYlhGeLclU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "EBrGXJbtLd6Y"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "metadata": {
        "id": "8VPCUsO-Lg9E"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
        "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "# creating optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# creating check point (Object-based saving)\n",
        "checkpoint_dir = './data_out/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ],
      "metadata": {
        "id": "nb-ek5-cLkay"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
        "        loss = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
        "            dec_hidden = enc_hidden\n",
        "            dec_input = tf.expand_dims([target2idx['<bos>']] * batch_size, 1)\n",
        "\n",
        "            for t in range(1, t_input.shape[1]):\n",
        "                predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
        "                loss += loss_function(t_input[:, t], predictions)\n",
        "                dec_input = tf.expand_dims(t_input[:, t], 1) #using teacher forcing\n",
        "\n",
        "        batch_loss = (loss / int(t_input.shape[1]))\n",
        "        total_loss += batch_loss\n",
        "        variables = encoder.variables + decoder.variables\n",
        "        gradient = tape.gradient(loss, variables)\n",
        "        optimizer.apply_gradients(zip(gradient, variables))\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch, total_loss / n_batch, batch_loss.numpy()))\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4pZ3gENLn7e",
        "outputId": "98db89b1-07d1-4642-f870-0c922717a782"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss 0.0396 Batch Loss 0.9912\n",
            "Epoch 10 Loss 0.0387 Batch Loss 0.9686\n",
            "Epoch 20 Loss 0.0375 Batch Loss 0.9377\n",
            "Epoch 30 Loss 0.0353 Batch Loss 0.8828\n",
            "Epoch 40 Loss 0.0313 Batch Loss 0.7816\n",
            "Epoch 50 Loss 0.0282 Batch Loss 0.7047\n",
            "Epoch 60 Loss 0.0251 Batch Loss 0.6286\n",
            "Epoch 70 Loss 0.0222 Batch Loss 0.5542\n",
            "Epoch 80 Loss 0.0192 Batch Loss 0.4801\n",
            "Epoch 90 Loss 0.0163 Batch Loss 0.4068\n",
            "Epoch 100 Loss 0.0135 Batch Loss 0.3370\n",
            "Epoch 110 Loss 0.0110 Batch Loss 0.2741\n",
            "Epoch 120 Loss 0.0089 Batch Loss 0.2216\n",
            "Epoch 130 Loss 0.0072 Batch Loss 0.1808\n",
            "Epoch 140 Loss 0.0060 Batch Loss 0.1508\n",
            "Epoch 150 Loss 0.0052 Batch Loss 0.1299\n",
            "Epoch 160 Loss 0.0046 Batch Loss 0.1156\n",
            "Epoch 170 Loss 0.0042 Batch Loss 0.1058\n",
            "Epoch 180 Loss 0.0039 Batch Loss 0.0987\n",
            "Epoch 190 Loss 0.0037 Batch Loss 0.0935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUxaS4-XLqOk",
        "outputId": "991eec32-018b-4f8e-b920-9f524b6dfa3e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7d14c8ec6a40>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'I feel hungry'"
      ],
      "metadata": {
        "id": "mmguQQosLr5K"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "\n",
        "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang['<bos>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += idx2target[predicted_id] + ' '\n",
        "\n",
        "        if idx2target.get(predicted_id) == '<eos>':\n",
        "            return result, sentence\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence\n",
        "\n",
        "result, output_sentence = prediction(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)\n",
        "\n",
        "print(sentence)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "RekaYjXeLttJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 12-6 Sequence to Sequence with attention"
      ],
      "metadata": {
        "id": "bAf59xBPMIaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV0qnDFPMZIe",
        "outputId": "a2a7b2c0-c63f-4476-c787-40ddc2e41492"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sources = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "targets = [['나는', '배가', '고프다'],\n",
        "           ['텐서플로우는', '매우', '어렵다'],\n",
        "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
        "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
      ],
      "metadata": {
        "id": "w87iCUzKOj-t"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary for sources\n",
        "s_vocab = list(set(sum(sources, [])))\n",
        "s_vocab.sort()\n",
        "s_vocab = ['<pad>'] + s_vocab\n",
        "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
        "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
        "\n",
        "pprint(source2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exTt_f3LOk9K",
        "outputId": "d5e69b1a-d2d6-432e-8793-6a068f3e1975"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0,\n",
            " 'I': 1,\n",
            " 'a': 2,\n",
            " 'changing': 3,\n",
            " 'deep': 4,\n",
            " 'difficult': 5,\n",
            " 'fast': 6,\n",
            " 'feel': 7,\n",
            " 'for': 8,\n",
            " 'framework': 9,\n",
            " 'hungry': 10,\n",
            " 'is': 11,\n",
            " 'learning': 12,\n",
            " 'tensorflow': 13,\n",
            " 'very': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary for targets\n",
        "t_vocab = list(set(sum(targets, [])))\n",
        "t_vocab.sort()\n",
        "t_vocab = ['<pad>', '<bos>', '<eos>'] + t_vocab\n",
        "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
        "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
        "\n",
        "pprint(target2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIgYJYysOmRZ",
        "outputId": "4c061bab-93bc-4af5-f56c-6521d594518e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<bos>': 1,\n",
            " '<eos>': 2,\n",
            " '<pad>': 0,\n",
            " '고프다': 3,\n",
            " '나는': 4,\n",
            " '딥러닝을': 5,\n",
            " '매우': 6,\n",
            " '배가': 7,\n",
            " '변화한다': 8,\n",
            " '빠르게': 9,\n",
            " '어렵다': 10,\n",
            " '위한': 11,\n",
            " '텐서플로우는': 12,\n",
            " '프레임워크이다': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
        "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
        "\n",
        "    if mode == 'source':\n",
        "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
        "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
        "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        return s_len, s_input\n",
        "\n",
        "    elif mode == 'target':\n",
        "        t_input = list(map(lambda sentence : ['<bos>'] + sentence + ['<eos>'], sequences))\n",
        "        t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
        "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
        "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "\n",
        "        t_output = list(map(lambda sentence : sentence + ['<eos>'], sequences))\n",
        "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
        "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "\n",
        "        return t_len, t_input, t_output"
      ],
      "metadata": {
        "id": "es11p1zAOoBK"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing for source\n",
        "s_max_len = 10\n",
        "s_len, s_input = preprocess(sequences = sources,\n",
        "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
        "print(s_len, s_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypwblA9uOqiX",
        "outputId": "80c0455d-0762-40ac-928a-7c48870bfd94"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing for target\n",
        "t_max_len = 12\n",
        "t_len, t_input, t_output = preprocess(sequences = targets, max_len = t_max_len, dic = target2idx, mode = 'target')\n",
        "print(t_len, t_input, t_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NmNQ907Or5T",
        "outputId": "c73b7836-5e4a-4115-d91d-28ab7d5d6349"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 5, 6, 6] [[ 1  4  7  3  2  0  0  0  0  0  0  0]\n",
            " [ 1 12  6 10  2  0  0  0  0  0  0  0]\n",
            " [ 1 12  5 11 13  2  0  0  0  0  0  0]\n",
            " [ 1 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
            " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
            " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
            " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hyper-param"
      ],
      "metadata": {
        "id": "35QT0Ju2OvMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters\n",
        "epochs = 100\n",
        "batch_size = 4\n",
        "learning_rate = .005\n",
        "total_step = epochs / batch_size\n",
        "buffer_size = 100\n",
        "n_batch = buffer_size//batch_size\n",
        "embedding_dim = 32\n",
        "units = 128\n",
        "\n",
        "# input\n",
        "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
        "data = data.shuffle(buffer_size = buffer_size)\n",
        "data = data.batch(batch_size = batch_size)"
      ],
      "metadata": {
        "id": "TsQWKNVJOtSE"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gru(units):\n",
        "    return tf.keras.layers.GRU(units,\n",
        "                               return_sequences=True,\n",
        "                               return_state=True,\n",
        "                               recurrent_activation='sigmoid',\n",
        "                               recurrent_initializer='glorot_uniform')"
      ],
      "metadata": {
        "id": "XXTj7lMpO7ly"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "I9eSwSuhO8kz"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        output, state = self.gru(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "metadata": {
        "id": "e9iHUbLLPD3x"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
        "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "# creating optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# creating check point (Object-based saving)\n",
        "checkpoint_dir = './data_out/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                encoder=encoder,\n",
        "                                decoder=decoder)\n",
        "\n",
        "# create writer for tensorboard\n",
        "summary_writer = tf.summary.create_file_writer(logdir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "b957tnjlPUYG"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
        "        loss = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
        "            dec_hidden = enc_hidden\n",
        "            dec_input = tf.expand_dims([target2idx['<bos>']] * batch_size, 1)\n",
        "\n",
        "            for t in range(1, t_input.shape[1]):\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "                loss += loss_function(t_input[:, t], predictions)\n",
        "                dec_input = tf.expand_dims(t_input[:, t], 1) #using teacher forcing\n",
        "\n",
        "        batch_loss = (loss / int(t_input.shape[1]))\n",
        "        total_loss += batch_loss\n",
        "        variables = encoder.variables + decoder.variables\n",
        "        gradient = tape.gradient(loss, variables)\n",
        "        optimizer.apply_gradients(zip(gradient, variables))\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch, total_loss / n_batch, batch_loss.numpy()))\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvPy3xZlPYhO",
        "outputId": "3022a80f-c9aa-4d0b-afcb-b323ff2dcca3"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss 0.0396 Batch Loss 0.9890\n",
            "Epoch 10 Loss 0.0377 Batch Loss 0.9428\n",
            "Epoch 20 Loss 0.0344 Batch Loss 0.8592\n",
            "Epoch 30 Loss 0.0328 Batch Loss 0.8200\n",
            "Epoch 40 Loss 0.0303 Batch Loss 0.7563\n",
            "Epoch 50 Loss 0.0241 Batch Loss 0.6019\n",
            "Epoch 60 Loss 0.0173 Batch Loss 0.4313\n",
            "Epoch 70 Loss 0.0127 Batch Loss 0.3171\n",
            "Epoch 80 Loss 0.0074 Batch Loss 0.1846\n",
            "Epoch 90 Loss 0.0041 Batch Loss 0.1019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang['<bos>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += idx2target[predicted_id] + ' '\n",
        "\n",
        "        if idx2target.get(predicted_id) == '<eos>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot\n"
      ],
      "metadata": {
        "id": "57QuEVUXPafM"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZokVBm_3Pud9"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "metadata": {
        "id": "eIX_3lX4PvCO"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aUcilkbPw7s",
        "outputId": "93d8b924-6eed-41fd-f7af-c98026af6d7d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7d14cd9c46a0>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'I feel hungry'\n",
        "\n",
        "translate(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w48mtRI7Pxdw",
        "outputId": "11244f2f-e38e-4b40-99f4-d8a408cd2f06"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-219babc300ac>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "<ipython-input-86-219babc300ac>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 45208 (\\N{HANGUL SYLLABLE NA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 45716 (\\N{HANGUL SYLLABLE NEUN}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48176 (\\N{HANGUL SYLLABLE BAE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 44256 (\\N{HANGUL SYLLABLE GO}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 54532 (\\N{HANGUL SYLLABLE PEU}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I feel hungry\n",
            "Predicted translation: 나는 배가 고프다 <eos> \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 12-7 Sequence to Sequence with attention chatbot"
      ],
      "metadata": {
        "id": "FCzq8HMsSbpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qoJqj9WSYKe",
        "outputId": "7e1a880c-c384-4c36-d069-6dbde8606ba6"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk\n",
        "!pip install konlpy JPype1-py3\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeu2LDOjWo_J",
        "outputId": "d0381abb-3f12-4d58-bfdd-52ac233e3991"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Connecting to ppa.launchp\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:11.2.0-1ubuntu1).\n",
            "g++ set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libice-dev librsvg2-common\n",
            "  libsm-dev libxkbfile1 libxt-dev libxtst6 libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  gvfs libice-doc libsm-doc libxt-doc openjdk-8-demo openjdk-8-source visualvm libnss-mdns\n",
            "  fonts-nanum fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei\n",
            "  fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libice-dev librsvg2-common\n",
            "  libsm-dev libxkbfile1 libxt-dev libxtst6 libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 22 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 50.0 MB of archives.\n",
            "After this operation, 169 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2 [125 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2 [2,037 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgail18 amd64 2.24.33-2ubuntu2 [15.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgail-common amd64 2.24.33-2ubuntu2 [132 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2 [7,932 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u382-ga-1~22.04.1 [30.8 MB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre amd64 8u382-ga-1~22.04.1 [75.4 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u382-ga-1~22.04.1 [8,851 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk amd64 8u382-ga-1~22.04.1 [3,943 kB]\n",
            "Fetched 50.0 MB in 1s (52.4 MB/s)\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../01-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../02-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../03-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../04-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../05-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../06-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../07-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../08-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../09-libgtk2.0-common_2.24.33-2ubuntu2_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../10-libgtk2.0-0_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../11-libgail18_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../12-libgail-common_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../13-libgtk2.0-bin_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../14-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../15-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../16-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../17-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../18-openjdk-8-jre-headless_8u382-ga-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../19-openjdk-8-jre_8u382-ga-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u382-ga-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../20-openjdk-8-jdk-headless_8u382-ga-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../21-openjdk-8-jdk_8u382-ga-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u382-ga-1~22.04.1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2) ...\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u382-ga-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u382-ga-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u382-ga-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.2) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Collecting JPype1-py3\n",
            "  Downloading JPype1-py3-0.5.5.4.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Building wheels for collected packages: JPype1-py3\n",
            "  Building wheel for JPype1-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for JPype1-py3: filename=JPype1_py3-0.5.5.4-cp310-cp310-linux_x86_64.whl size=3258010 sha256=bb1567bace8b17c41aece845e3a144694d0e8f68d6d2fee81932931dc337cd2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/72/ea/b886a286a27c6e3c35ba9e9833b13abc5c5bdc0a9cad91e328\n",
            "Successfully built JPype1-py3\n",
            "Installing collected packages: JPype1-py3\n",
            "Successfully installed JPype1-py3-0.5.5.4\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "Install mecab-python\n",
            "/tmp /content\n",
            "/content\n",
            "Processing /tmp/mecab-python-0.996\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Twitter\n",
        "import pandas as pd\n",
        "import enum\n",
        "import os\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1pEO8NtBSz4b"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadData():\n",
        "    dataDF = pd.read_csv('/content/ChatBotData.csv', header=0)\n",
        "    question, answer = list(dataDF['Q']), list(dataDF['A'])\n",
        "    return question, answer\n",
        "\n",
        "def preproLikeMorphlized(data):\n",
        "    morphAnalyzer = Twitter()\n",
        "    result_data = list()\n",
        "\n",
        "    for seq in data:\n",
        "        morphlizedSeq = \" \".join(morphAnalyzer.morphs(seq.replace(' ', '')))\n",
        "        result_data.append(morphlizedSeq)\n",
        "\n",
        "    return result_data\n",
        "\n",
        "def dataTokenizer(data):\n",
        "    words = []\n",
        "    for sentence in data:\n",
        "        sentence = re.sub(change_filter, \"\", sentence)\n",
        "        for word in sentence.split():\n",
        "            words.append(word)\n",
        "    return [word for word in words if word]\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = w.rstrip().strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "\n",
        "    return w\n",
        "\n",
        "def create_dataset(data, num_examples):\n",
        "    word_pairs = [[preprocess_sentence(l)]  for l in data[:num_examples]]\n",
        "    return word_pairs\n",
        "\n",
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "\n",
        "        self.create_index()\n",
        "\n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        self.word2idx['<pad>'] = 0\n",
        "\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1\n",
        "\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word\n",
        "\n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "def load_dataset(path, num_examples):\n",
        "    data_df = pd.read_csv(path, header=0)\n",
        "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
        "    question = create_dataset(question, num_examples)\n",
        "    answer = create_dataset(answer, num_examples)\n",
        "\n",
        "    print(len(question))\n",
        "\n",
        "    pairs = [question[i] + answer[i] for i in range(num_examples)]\n",
        "    inp_lang = LanguageIndex(q for q, a in pairs)\n",
        "    targ_lang = LanguageIndex(a for q, a in pairs)\n",
        "    input_tensor = [[inp_lang.word2idx[s] for s in q.split(' ')] for q, a in pairs]\n",
        "    target_tensor = [[targ_lang.word2idx[s] for s in a.split(' ')] for q, a in pairs]\n",
        "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, maxlen=max_length_inp, padding='post')\n",
        "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, maxlen=max_length_tar, padding='post')\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar\n",
        "\n",
        "num_examples = 11823\n",
        "\n",
        "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset('/content/ChatBotData.csv', num_examples)\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bADuAEWEWL0o",
        "outputId": "4a5b8d31-e9ab-4d85-ccc3-a26e0ac89038"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11823\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9458, 9458, 2365, 2365)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a tf.dataset"
      ],
      "metadata": {
        "id": "vYKpDL4sa5u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "byAwc3IgX-IW"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gru(units):\n",
        "    return tf.keras.layers.GRU(units,\n",
        "                               return_sequences=True,\n",
        "                               return_state=True,\n",
        "                               recurrent_activation='sigmoid',\n",
        "                               recurrent_initializer='glorot_uniform')"
      ],
      "metadata": {
        "id": "mwsKRQQRa9en"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        print(\"state: {}\".format(state.shape))\n",
        "        print(\"output: {}\".format(state.shape))\n",
        "\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "B2KH1CRLbBpH"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        output, state = self.gru(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "metadata": {
        "id": "oNdI3l6wbFK6"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab_inp_size, vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DKG2Q2HbXRN",
        "outputId": "7fac3001-5433-4d21-a2ec-210071fd19ee"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13422 9856 256 1024 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the optimizer and the loss function"
      ],
      "metadata": {
        "id": "n6hoJHgQbYLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.legacy.Adam()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "Vw1Az6iAbcpL"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checkpoints (Object-based saving)"
      ],
      "metadata": {
        "id": "VEEQ0Hv_bep4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './data_out/training_checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "metadata": {
        "id": "4vqC1cbBbiwV"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "d1dG1f3YbjjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(inp, hidden)\n",
        "            dec_hidden = enc_hidden\n",
        "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "                loss += loss_function(targ[:, t], predictions)\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        total_loss += batch_loss\n",
        "        variables = encoder.variables + decoder.variables\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "\n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "          checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f7_cDSPbmeg",
        "outputId": "e866bf54-d28c-4cf1-fe76-ae77659a04c3"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "Epoch 1 Batch 0 Loss 1.9893\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "Epoch 1 Batch 100 Loss 1.3120\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "state: (64, 1024)\n",
            "output: (64, 1024)\n",
            "Epoch 1 Loss 1.3383\n",
            "Time taken for 1 epoch 1476.4033992290497 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        # storing the attention weigths to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.idx2word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "metadata": {
        "id": "K4MFvW16cIAG"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "M6PTcMvhcN9P"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "metadata": {
        "id": "37RJTYYocSSv"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate('뭐라도 배워볼까.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ru84IlkkdQhC",
        "outputId": "69b14815-65a1-4a78-9b4c-26e15b937b7a"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-129-219babc300ac>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
            "<ipython-input-129-219babc300ac>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 47952 (\\N{HANGUL SYLLABLE MWEO}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 46972 (\\N{HANGUL SYLLABLE RA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48176 (\\N{HANGUL SYLLABLE BAE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 50892 (\\N{HANGUL SYLLABLE WEO}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48380 (\\N{HANGUL SYLLABLE BOL}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 44620 (\\N{HANGUL SYLLABLE GGA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state: (1, 1024)\n",
            "output: (1, 1024)\n",
            "Input: <start> 뭐라도 배워볼까 . <end>\n",
            "Predicted translation: . . <end> \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'AppleGothic' not found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}