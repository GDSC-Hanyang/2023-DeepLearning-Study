{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5WZRbwWBfPQUR7LPvdwrB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#실행중인 운영체제 확인\n","\n","import platform\n","print(platform.platform())\n","\n","# 파이썬 버전\n","import sys\n","print(sys.version_info)\n","\n","# matplotlib 주요 설치 정보\n","\n","import matplotlib\n","\n","print ('버전: ', matplotlib.__version__)\n","print ('설치위치: ', matplotlib.__file__)\n","print ('설정: ', matplotlib.get_configdir())\n","print ('캐시: ', matplotlib.get_cachedir())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmP6VHEAHLra","executionInfo":{"status":"ok","timestamp":1698846328364,"user_tz":-540,"elapsed":340,"user":{"displayName":"이재승","userId":"06759334452558132573"}},"outputId":"e389865d-68f9-40b3-cb2f-689747d1b91f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Linux-5.15.120+-x86_64-with-glibc2.35\n","sys.version_info(major=3, minor=10, micro=12, releaselevel='final', serial=0)\n","버전:  3.7.1\n","설치위치:  /usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\n","설정:  /root/.config/matplotlib\n","캐시:  /root/.cache/matplotlib\n"]}]},{"cell_type":"code","execution_count":19,"metadata":{"id":"4jNBM8YkHAIe","executionInfo":{"status":"ok","timestamp":1698846328705,"user_tz":-540,"elapsed":3,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"outputs":[],"source":["from __future__ import absolute_import, division, print_function\n","\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","\n","### matplotlib 한글 폰트 설정 #############################\n","from matplotlib import font_manager, rc\n","## for window #####\n","# font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n","# rc('font', family=font_name)\n","## for mac #####\n","rc('font', family='monospace') #for mac\n","## linux는 맨 아래 code 참고 #####\n","\n","from sklearn.model_selection import train_test_split\n","\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import time\n"]},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kkD54UiFHka1","executionInfo":{"status":"ok","timestamp":1698846335394,"user_tz":-540,"elapsed":6317,"user":{"displayName":"이재승","userId":"06759334452558132573"}},"outputId":"0fc25f42-4428-470b-9929-bbf378cd41b8"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n"]}]},{"cell_type":"code","source":["from konlpy.tag import Twitter\n","import pandas as pd\n","import enum\n","import os\n","import re\n","from sklearn.model_selection import train_test_split\n","import numpy as np"],"metadata":{"id":"wJDvcdZzHFi5","executionInfo":{"status":"ok","timestamp":1698846335394,"user_tz":-540,"elapsed":11,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"j0gLzmEaH9oN","executionInfo":{"status":"ok","timestamp":1698846335394,"user_tz":-540,"elapsed":10,"user":{"displayName":"이재승","userId":"06759334452558132573"}},"outputId":"6441d0c5-41e1-41f6-8c4d-fe8c0e4bb231"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["def loadData():\n","    # 판다스를 통해서 데이터를 불러온다.\n","    dataDF = pd.read_csv('./ChatBotData.csv', header=0)\n","    # 질문과 답변 열을 가져와 question과 answer에 넣는다.\n","    question, answer = list(dataDF['Q']), list(dataDF['A'])\n","#     dataset = dataDF['Q'] + '\\t' + dataDF['A']\n","#     dataset = list(dataset)\n","    # skleran에서 지원하는 함수를 통해서 학습 셋과\n","    # 테스트 셋을 나눈다.\n","#     xTrain, xTest, yTrain, yTest = train_test_split(question, answer, test_size=0.33, random_state=42)\n","    # 그 값을 리턴한다.\n","#     return xTrain, yTrain, xTest, yTest\n","    return question, answer\n","\n","def preproLikeMorphlized(data):\n","    # 형태소 분석 모듈 객체를\n","    # 생성합니다.\n","\n","    morphAnalyzer = Twitter()\n","    # 형태소 토크나이즈 결과 문장을 받을\n","    #  리스트를 생성합니다.\n","    result_data = list()\n","    # 데이터에 있는 매 문장에 대해 토크나이즈를\n","    # 할 수 있도록 반복문을 선언합니다.\n","    for seq in data:\n","        # Twitter.morphs 함수를 통해 토크나이즈 된\n","        # 리스트 객체를 받고 다시 공백문자를 기준으로\n","        # 하여 문자열로 재구성 해줍니다.\n","        morphlizedSeq = \" \".join(morphAnalyzer.morphs(seq.replace(' ', '')))\n","        result_data.append(morphlizedSeq)\n","\n","    return result_data\n","\n","def dataTokenizer(data):\n","    # 토크나이징 해서 담을 배열 생성\n","    words = []\n","    for sentence in data:\n","        # FILTERS = \"([~.,!?\\\"':;)(])\"\n","        # 위 필터와 같은 값들을 정규화 표현식을\n","        # 통해서 모두 \"\" 으로 변환 해주는 부분이다.\n","        sentence = re.sub(change_filter, \"\", sentence)\n","        for word in sentence.split():\n","            words.append(word)\n","    # 토그나이징과 정규표현식을 통해 만들어진\n","    # 값들을 넘겨 준다.\n","    return [word for word in words if word]\n","\n","def preprocess_sentence(w):\n","\n","    # creating a space between a word and the punctuation following it\n","    # eg: \"he is a boy.\" => \"he is a boy .\"\n","    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","    w = re.sub(r'[\" \"]+', \" \", w)\n","\n","    w = w.rstrip().strip()\n","\n","    # adding a start and an end token to the sentence\n","    # so that the model know when to start and stop predicting.\n","    w = '<start> ' + w + ' <end>'\n","\n","    return w\n","\n","def create_dataset(data, num_examples):\n","#     word_pairs = [[preprocess_sentence(w) for w in l]  for l in data[:num_examples]]\n","    word_pairs = [[preprocess_sentence(l)]  for l in data[:num_examples]]\n","    return word_pairs\n","\n","class LanguageIndex():\n","    def __init__(self, lang):\n","        self.lang = lang\n","        self.word2idx = {}\n","        self.idx2word = {}\n","        self.vocab = set()\n","\n","        self.create_index()\n","\n","    def create_index(self):\n","        for phrase in self.lang:\n","#             if self.vocab == '<start>':\n","#                 pass\n","            self.vocab.update(phrase.split(' '))\n","\n","        self.vocab = sorted(self.vocab)\n","\n","        self.word2idx['<pad>'] = 0\n","#         self.word2idx['<start>'] = 1\n","#         self.word2idx['<end>'] = 2\n","#         self.word2idx['<unk>'] = 3\n","\n","        for index, word in enumerate(self.vocab):\n","            self.word2idx[word] = index + 1\n","\n","        for word, index in self.word2idx.items():\n","            self.idx2word[index] = word\n","\n","def max_length(tensor):\n","    return max(len(t) for t in tensor)"],"metadata":{"id":"tSTnQW5hHjS5","executionInfo":{"status":"ok","timestamp":1698846335394,"user_tz":-540,"elapsed":7,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def load_dataset(path, num_examples):\n","\n","    # 판다스를 통해서 데이터를 불러온다.\n","    data_df = pd.read_csv(path, header=0)\n","    # 질문과 답변 열을 가져와 question과 answer에 넣는다.\n","    question, answer = list(data_df['Q']), list(data_df['A'])\n","\n","    question = create_dataset(question, num_examples)\n","    answer = create_dataset(answer, num_examples)\n","\n","    print(len(question))\n","\n","    pairs = [question[i] + answer[i] for i in range(num_examples)]\n","\n","    # index language using the class defined above\n","    inp_lang = LanguageIndex(q for q, a in pairs)\n","    targ_lang = LanguageIndex(a for q, a in pairs)\n","\n","    # Vectorize the input and target languages\n","\n","    # question\n","    input_tensor = [[inp_lang.word2idx[s] for s in q.split(' ')] for q, a in pairs]\n","\n","    # answer\n","    target_tensor = [[targ_lang.word2idx[s] for s in a.split(' ')] for q, a in pairs]\n","\n","    # Calculate max_length of input and output tensor\n","    # Here, we'll set those to the longest sentence in the dataset\n","    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n","\n","    # Padding the input and output tensor to the maximum length\n","    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor,\n","                                                                 maxlen=max_length_inp,\n","                                                                 padding='post')\n","\n","    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor,\n","                                                                  maxlen=max_length_tar,\n","                                                                  padding='post')\n","\n","    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"],"metadata":{"id":"jTtGWQ91Hqy3","executionInfo":{"status":"ok","timestamp":1698846335394,"user_tz":-540,"elapsed":7,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Load dataset with limit\n","\n","num_examples = 11823\n","\n","input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset('./ChatBotData.csv', num_examples)\n","\n","# Creating training and validation sets using an 80-20 split\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n","\n","# Show length\n","len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pv1ywAhuHuCy","executionInfo":{"status":"ok","timestamp":1698846335976,"user_tz":-540,"elapsed":589,"user":{"displayName":"이재승","userId":"06759334452558132573"}},"outputId":"a37a8215-0271-4551-a5f1-e78fb49394ab"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["11823\n"]},{"output_type":"execute_result","data":{"text/plain":["(9458, 9458, 2365, 2365)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["max_length_targ"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zAKsL9pBHwU6","executionInfo":{"status":"ok","timestamp":1698846342350,"user_tz":-540,"elapsed":4,"user":{"displayName":"이재승","userId":"06759334452558132573"}},"outputId":"e2fe3d14-b3b0-4843-f00a-af555650986a"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 64\n","N_BATCH = BUFFER_SIZE//BATCH_SIZE\n","embedding_dim = 256\n","units = 1024\n","vocab_inp_size = len(inp_lang.word2idx)\n","vocab_tar_size = len(targ_lang.word2idx)\n","\n","dataset = tf.data.Dataset.from_tensor_slices(\n","    (input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","#drop_reainder가 True이면, batch size가 적지 않도록 수정\n","\n","# The tensors in the resulting element will have an additional outer dimension,\n","# which will be batch_size (or N % batch_size for the last element if batch_size\n","# does not divide the number of input elements N evenly and drop_remainder\n","# is False). If your program depends on the batches having the same outer dimension,\n","# you should set the drop_remainder argument to True to prevent the smaller batch\n","# from being produced."],"metadata":{"id":"hsj7vDlNIfls","executionInfo":{"status":"ok","timestamp":1698846404468,"user_tz":-540,"elapsed":339,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def gru(units):\n","    return tf.keras.layers.GRU(units,\n","                               return_sequences=True,\n","                               return_state=True,\n","                               recurrent_activation='sigmoid',\n","                               recurrent_initializer='glorot_uniform')"],"metadata":{"id":"woTvrHemIhF0","executionInfo":{"status":"ok","timestamp":1698846405894,"user_tz":-540,"elapsed":4,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["class Encoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","        super(Encoder, self).__init__()\n","        self.batch_sz = batch_sz\n","        self.enc_units = enc_units\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.gru = gru(self.enc_units)\n","\n","    def call(self, x, hidden):\n","        x = self.embedding(x)\n","        output, state = self.gru(x, initial_state = hidden)\n","        print(\"state: {}\".format(state.shape))\n","        print(\"output: {}\".format(state.shape))\n","\n","        return output, state\n","\n","    def initialize_hidden_state(self):\n","        return tf.zeros((self.batch_sz, self.enc_units))"],"metadata":{"id":"6bHFIE_fIjmU","executionInfo":{"status":"ok","timestamp":1698846412119,"user_tz":-540,"elapsed":407,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["class Decoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","        super(Decoder, self).__init__()\n","        self.batch_sz = batch_sz\n","        self.dec_units = dec_units\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.gru = gru(self.dec_units)\n","        self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","        # used for attention\n","        self.W1 = tf.keras.layers.Dense(self.dec_units)\n","        self.W2 = tf.keras.layers.Dense(self.dec_units)\n","        self.V = tf.keras.layers.Dense(1)\n","\n","    def call(self, x, hidden, enc_output):\n","        # enc_output shape == (batch_size, max_length, hidden_size)\n","\n","        # hidden shape == (batch_size, hidden size)\n","        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n","        # we are doing this to perform addition to calculate the score\n","        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n","        # * `score = FC(tanh(FC(EO) + FC(H)))`\n","        # score shape == (batch_size, max_length, 1)\n","        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n","        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n","\n","        #* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, 1)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n","        # attention_weights shape == (batch_size, max_length, 1)\n","        attention_weights = tf.nn.softmax(score, axis=1)\n","\n","        # context_vector shape after sum == (batch_size, hidden_size)\n","        # * `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n","        context_vector = attention_weights * enc_output\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","        # * `embedding output` = The input to the decoder X is passed through an embedding layer.\n","        x = self.embedding(x)\n","\n","        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","        # * `merged vector = concat(embedding output, context vector)`\n","        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","        # passing the concatenated vector to the GRU\n","        output, state = self.gru(x)\n","\n","        # output shape == (batch_size * 1, hidden_size)\n","        output = tf.reshape(output, (-1, output.shape[2]))\n","\n","        # output shape == (batch_size * 1, vocab)\n","        x = self.fc(output)\n","\n","        return x, state, attention_weights\n","\n","    def initialize_hidden_state(self):\n","        return tf.zeros((self.batch_sz, self.dec_units))"],"metadata":{"id":"bwk0A76vIwgY","executionInfo":{"status":"ok","timestamp":1698846419863,"user_tz":-540,"elapsed":412,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["print(vocab_inp_size, vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","\n","encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TfxZfJQIycQ","executionInfo":{"status":"ok","timestamp":1698846425602,"user_tz":-540,"elapsed":6,"user":{"displayName":"이재승","userId":"06759334452558132573"}},"outputId":"0cd08594-b577-4586-e01c-e8037b25eef1"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["13422 9856 256 1024 64\n"]}]},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam()\n","\n","def loss_function(real, pred):\n","    mask = 1 - np.equal(real, 0)\n","    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n","\n","#     print(\"real: {}\".format(real))\n","#     print(\"pred: {}\".format(pred))\n","#     print(\"mask: {}\".format(mask))\n","#     print(\"loss: {}\".format(tf.reduce_mean(loss_)))\n","\n","    return tf.reduce_mean(loss_)"],"metadata":{"id":"8mQI7QW4Iz18","executionInfo":{"status":"ok","timestamp":1698846432468,"user_tz":-540,"elapsed":331,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["checkpoint_dir = './data_out/training_checkpoints'\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"metadata":{"id":"HJLphHUzI1cw","executionInfo":{"status":"ok","timestamp":1698846437793,"user_tz":-540,"elapsed":4,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 1\n","\n","#GPU 설정\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    hidden = encoder.initialize_hidden_state()\n","    total_loss = 0\n","\n","    for (batch, (inp, targ)) in enumerate(dataset):\n","        loss = 0\n","\n","        with tf.GradientTape() as tape:\n","            enc_output, enc_hidden = encoder(inp, hidden)\n","\n","            dec_hidden = enc_hidden\n","\n","            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)\n","\n","            # Teacher forcing - feeding the target as the next input\n","            for t in range(1, targ.shape[1]):\n","                # passing enc_output to the decoder\n","                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","                loss += loss_function(targ[:, t], predictions)\n","\n","                # using teacher forcing\n","                dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","        batch_loss = (loss / int(targ.shape[1]))\n","\n","        total_loss += batch_loss\n","\n","        variables = encoder.variables + decoder.variables\n","\n","        gradients = tape.gradient(loss, variables)\n","\n","        optimizer.apply_gradients(zip(gradients, variables))\n","\n","        if batch % 100 == 0:\n","            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                         batch,\n","                                                         batch_loss.numpy()))\n","    # saving (checkpoint) the model every 2 epochs\n","    if (epoch + 1) % 2 == 0:\n","          checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                        total_loss / N_BATCH))\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E21QeViQI20F","executionInfo":{"status":"ok","timestamp":1698848210732,"user_tz":-540,"elapsed":1762708,"user":{"displayName":"이재승","userId":"06759334452558132573"}},"outputId":"87baebc8-2933-4bdb-e3a5-ad336d77ccbe"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["state: (64, 1024)\n","output: (64, 1024)\n","Epoch 1 Batch 0 Loss 2.0946\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","Epoch 1 Batch 100 Loss 1.2946\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","state: (64, 1024)\n","output: (64, 1024)\n","Epoch 1 Loss 1.3216\n","Time taken for 1 epoch 1761.9595410823822 sec\n","\n"]}]},{"cell_type":"code","source":["def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n","    attention_plot = np.zeros((max_length_targ, max_length_inp))\n","\n","    sentence = preprocess_sentence(sentence)\n","\n","    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n","    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n","    inputs = tf.convert_to_tensor(inputs)\n","\n","    result = ''\n","\n","    hidden = [tf.zeros((1, units))]\n","    enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","    dec_hidden = enc_hidden\n","    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n","\n","    for t in range(max_length_targ):\n","        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n","\n","        # storing the attention weigths to plot later on\n","        attention_weights = tf.reshape(attention_weights, (-1, ))\n","        attention_plot[t] = attention_weights.numpy()\n","\n","        predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","        result += targ_lang.idx2word[predicted_id] + ' '\n","\n","        if targ_lang.idx2word[predicted_id] == '<end>':\n","            return result, sentence, attention_plot\n","\n","        # the predicted ID is fed back into the model\n","        dec_input = tf.expand_dims([predicted_id], 0)\n","\n","    return result, sentence, attention_plot\n"],"metadata":{"id":"YvuNzEczI5Ib","executionInfo":{"status":"ok","timestamp":1698848210732,"user_tz":-540,"elapsed":4,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# function for plotting the attention weights\n","def plot_attention(attention, sentence, predicted_sentence):\n","    fig = plt.figure(figsize=(10,10))\n","    ax = fig.add_subplot(1, 1, 1)\n","    ax.matshow(attention, cmap='viridis')\n","\n","    fontdict = {'fontsize': 14}\n","\n","    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","\n","    plt.show()"],"metadata":{"id":"m1PdAl-rI7dd","executionInfo":{"status":"ok","timestamp":1698848210732,"user_tz":-540,"elapsed":3,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n","    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n","\n","    print('Input: {}'.format(sentence))\n","    print('Predicted translation: {}'.format(result))\n","\n","    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"],"metadata":{"id":"72K6d8UCI80N","executionInfo":{"status":"ok","timestamp":1698848210732,"user_tz":-540,"elapsed":3,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# restoring the latest checkpoint in checkpoint_dir\n","checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_r0Pjm9FI97y","executionInfo":{"status":"ok","timestamp":1698848210732,"user_tz":-540,"elapsed":3,"user":{"displayName":"이재승","userId":"06759334452558132573"}},"outputId":"f60b216c-e531-4131-e231-ad47ad7f191d"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.InitializationOnlyStatus at 0x7909e0263c70>"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["translate('뭐라도 배워볼까.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"bP0K3aRTI_OZ","executionInfo":{"status":"ok","timestamp":1698848211307,"user_tz":-540,"elapsed":577,"user":{"displayName":"이재승","userId":"06759334452558132573"}},"outputId":"95aae195-5b63-4996-b603-0ee3aa066de7"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["state: (1, 1024)\n","output: (1, 1024)\n","Input: <start> 뭐라도 배워볼까 . <end>\n","Predicted translation: 좋은 . <end> \n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-38-219babc300ac>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","<ipython-input-38-219babc300ac>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 47952 (\\N{HANGUL SYLLABLE MWEO}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 46972 (\\N{HANGUL SYLLABLE RA}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48176 (\\N{HANGUL SYLLABLE BAE}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 50892 (\\N{HANGUL SYLLABLE WEO}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48380 (\\N{HANGUL SYLLABLE BOL}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 44620 (\\N{HANGUL SYLLABLE GGA}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 51339 (\\N{HANGUL SYLLABLE JOH}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n","/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 51008 (\\N{HANGUL SYLLABLE EUN}) missing from current font.\n","  fig.canvas.print_figure(bytes_io, **kw)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x1000 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"PNgLwqqPJAyT"},"execution_count":null,"outputs":[]}]}