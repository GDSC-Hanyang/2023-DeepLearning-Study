{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 11-1: ConvNet의 Conv layer 만들기**"
      ],
      "metadata": {
        "id": "inGjULCdVAr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**History**  \n",
        "&rarr; 고양이가 사물을 인식할 때 시각 뉴런이 부분적으로 사물을 파악하는 과정에서 착안하여 만들어짐"
      ],
      "metadata": {
        "id": "VMNIj5pyVCdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Convolutional Neural Network (CNN)**  \n",
        "- Conv(+ReLU) layer &rarr; Pooling layer &rarr; Fully Connection 과정으로 진행됨  <br><br>\n",
        "<img src=\"https://blog.kakaocdn.net/dn/cu663I/btqwhMjVPJs/eNPZuDS7kBtOrr7AmXbyW1/img.png\"><br><br>\n"
      ],
      "metadata": {
        "id": "OMlP8VM8VeK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Convolution Layer**<br>\n",
        "<img src=\"https://anhreynolds.com/img/cnn.png\"><br>\n",
        "- weigth를 가진 3 X 3 filter를 이동시키면서 하나의 number로 계산시켜 부분적으 학습하는 layer  \n",
        "- $Wx + b$에 ReLU를 바로 적용해서 $ReLU(Wx + b)$로 바로 적용하기도 한다  \n",
        "\n",
        ">**한 번 연산시, 얻을 수 있는 number 의 개수**  \n",
        "- 위의 예제를 보면 6 X 6 이미지에서 3 X 3 filter을 적용했다  \n",
        "- stride(filter를 움직일때, 몇 칸을 움직이는지에 대한 변수)가 1이다  \n",
        "- (6 - 3)/1 + 1 = 4  \n",
        "- 즉, N X N 형태의 이미지를 F X F 형태의 filter로 stride만큼 이동할때 $\\frac{( N - F )}{stride} + 1$이다  "
      ],
      "metadata": {
        "id": "IujTQea1V2A7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Padding**  \n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:325/1*b77nZmPH15dE8g49BLW20A.png\">  \n",
        "- 계속해서 CONV filter를 적용할 경우 이미지의 크기가 작아진다  \n",
        "- 이를 방지하기 위해서 기존 이미지 테두리에 0을 넣은 다음 연산을 진행시키는 과정을 padding이라고 한다  \n",
        "- ex) 7 X 7 이미지를 1px padding을 시키면 9 X 9 이미지가 출력된다  "
      ],
      "metadata": {
        "id": "lDnchOfBWKRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Activation maps**  \n",
        "<img src = \"https://i.stack.imgur.com/V2DHY.png\" width=500 heigth=300>  \n",
        "- 여러개의 filter를 만들어서 하나의 이미지에 여러가지 filter를 적용시킨 후 나온 결과 이미지의 집합을 activation map이라고 한다  \n",
        "- 위 예제에서 filter의 개수가 2개이므로 차원은 28 X 28 X 2가 된다  \n",
        "- activation map에서 마지막 차원은 filter의 개수로 결정된다  \n",
        "- Weight 값의 개수는 5 * 5 * 3 * 2 가 된다  \n"
      ],
      "metadata": {
        "id": "Lkm421VnXAHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 11-2: Conv Net Max Pooling과 Fullnetwork**"
      ],
      "metadata": {
        "id": "ql_zO6wG35n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Pooling Layer (Sampling)**  \n",
        "<img src=\"https://static.javatpoint.com/tutorial/pytorch/images/pytorch-convolutional-neural-network8.png\" width=500 height=300>  \n",
        "- convolutional layer에서 하나의 layer를 추출해서 resize하고 다시 합치는 과정  \n",
        "- pooling layer를 Sampling 이라고 한다"
      ],
      "metadata": {
        "id": "QH9Oh9_0sN6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Max Pooling**<br><br>\n",
        "<img src=\"https://images.deepai.org/glossary-terms/4b19331a4b0a455cbefd00488dfc4ef4/max_pooling_jpg.jpg\" width=450 height=200><br><br>\n",
        "- 만약 pooling layer 크기가 2 X 2라고 하면 근처 4개의 값 중에서 가장 큰 값을 추출하는 과정을 max pooling이라고 한다  \n",
        "- 노이즈가 감소하고 영상 분별력이 좋아진다  \n",
        "- 탐색 속도를 높이고자 했지만 이미지 구성 요소간의 공간관계에 대한 정보를 잃는다  \n",
        "\n",
        "> **Global Average Pooling**  \n",
        "<img src=\"https://www.baeldung.com/wp-content/uploads/sites/4/2023/03/maxpooling-e1663354281314.jpg\"><br><br>\n",
        "- 각 node의 평균 값을 feature 값으로 취한다  \n",
        "- 계산 속도가 느리다  \n",
        "\n",
        ">**왜 Min Pooling은 없을까?**  \n",
        "- 일반적으로 Activation function은 0이하 값들을 0으로 취급하기 때문에 의미있는 정보만을 남겨서 처리할 수 없게 된다  \n",
        "\n"
      ],
      "metadata": {
        "id": "jzFJIs1cvFBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lectrue 11-3: ConvNet의 활용 예**"
      ],
      "metadata": {
        "id": "WqPZ94374G-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**LeNet-5**  \n",
        "<img src=\"https://i.imgur.com/tQGDtMp.jpg\">\n",
        "- Lecan: 초기 CNN 창시자  \n",
        "- Conv filter 5 X 5, stride 1  \n",
        "- Subscaling(sampling) 2 X 2, stride 2  \n"
      ],
      "metadata": {
        "id": "LYMtpVpn12ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**AlexNet(2012)**<br><br>\n",
        "<img src=\"https://www.mdpi.com/remotesensing/remotesensing-09-00848/article_deploy/html/images/remotesensing-09-00848-g001.png\"><br><br>\n",
        "- Input: 227 x 227 X 3  \n",
        "- Conv filter: 96개 11 X 11 X 3, stride 4  \n",
        "- Pooling filter: 3 X 3 filters, stride 2  \n",
        "- Normalization이 사용되었지만 큰 의미는 주지 않았다  \n",
        "- 처음으로 ReLU함수가 개발되었다  \n",
        "- dropout 0.5 , batch 128  \n",
        "- 7 CNN Asssemble"
      ],
      "metadata": {
        "id": "oiQioM-32qo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**GoogleNet**<br><br>\n",
        "<img src=\"https://blog.kakaocdn.net/dn/Iq9NO/btqyPWk5PBX/K2JicGjIjj5w0eFIbhx4bK/img.png\"><br><br>\n",
        "- 중산중간 convolution layer와 pooling을 한 사진을 다시 합성하여 여러가지 조합"
      ],
      "metadata": {
        "id": "-Wxp46RvAh73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**ResNet**  \n",
        "<img src=\"https://images.velog.io/images/junyoung9696/post/3137e50c-b52f-4cdd-8ae8-2faf497efe84/r10.png\" height=300><br><br>\n",
        "- 중간에 어떤 것은 띄어넘고 연산을 진행해서 연산속도를 증진 시키고 152개 layer를 두면서 정확도를 높였다  "
      ],
      "metadata": {
        "id": "hl9VmNfNBMw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Lab 11-0: CNN Basic**"
      ],
      "metadata": {
        "id": "EB5vxC-pBlBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "XB95p9aBVbBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Convolution**   \n",
        "- <b>conv2d = keras.layers.Conv2D(filters=1, kernel_size=2, padding='VALID',\n",
        "                             kernel_initializer=weight_init)(image)<br><br>\n",
        "<img src=\"https://cloud.githubusercontent.com/assets/901975/24833375/c0d9c262-1cf9-11e7-9efc-5dd6fe0fedb0.png\" height = 300>  "
      ],
      "metadata": {
        "id": "C5irYE3DDAB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.constant([[[[1],[2],[3]],\n",
        "                   [[4],[5],[6]],\n",
        "                   [[7],[8],[9]]]], dtype=np.float32)\n",
        "print(image.shape)\n",
        "plt.imshow(image.numpy().reshape(3,3), cmap='Greys')\n",
        "plt.show()\n",
        "print(\"image.shape\", image.shape)\n",
        "weight = np.array([[[[1.]],[[1.]]],\n",
        "                   [[[1.]],[[1.]]]])\n",
        "print(\"weight.shape\", weight.shape)\n",
        "weight_init = tf.constant_initializer(weight)\n",
        "conv2d = keras.layers.Conv2D(filters=1, kernel_size=2, padding='VALID',\n",
        "                             kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "print(conv2d.numpy().reshape(2,2))\n",
        "plt.imshow(conv2d.numpy().reshape(2,2), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VvoZyUlaCuUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**3 filters**  \n",
        "- <b>conv2d = keras.layers.Conv2D(filters=3, kernel_size=2, padding='SAME',\n",
        "kernel_initializer=weight_init)"
      ],
      "metadata": {
        "id": "mRsKy0uRDrIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"imag:\\n\", image)\n",
        "print(\"image.shape\", image.shape)\n",
        "\n",
        "weight = np.array([[[[1.,10.,-1.]],[[1.,10.,-1.]]],\n",
        "                   [[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
        "print(\"weight.shape\", weight.shape)\n",
        "weight_init = tf.constant_initializer(weight)\n",
        "conv2d = keras.layers.Conv2D(filters=3, kernel_size=2, padding='SAME',\n",
        "                             kernel_initializer=weight_init)(image)\n",
        "print(\"conv2d.shape\", conv2d.shape)\n",
        "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
        "for i, feature_map in enumerate(feature_maps):\n",
        "    print(feature_map.reshape(3,3))\n",
        "    plt.subplot(1,3,i+1), plt.imshow(feature_map.reshape(3,3), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kbgb4k_cDkN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Maxpooling**  \n",
        "<b>keras.layers.MaxPool2D(pool_size=(2,2), strides=1, padding='VALID')(image)"
      ],
      "metadata": {
        "id": "ZlEWKgEOD0Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.constant([[[[4],[3]],\n",
        "                    [[2],[1]]]], dtype=np.float32)\n",
        "pool = keras.layers.MaxPool2D(pool_size=(2,2), strides=1, padding='VALID')(image)\n",
        "print(pool.shape)\n",
        "print(pool.numpy())"
      ],
      "metadata": {
        "id": "63gbXILnDtYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**0 Padding**  \n",
        "- <b> pool = keras.layers.MaxPool2D(pool_size=(2,2), strides=1, padding='SAME')"
      ],
      "metadata": {
        "id": "wvZz2s6aEcej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = tf.constant([[[[4],[3]],\n",
        "                    [[2],[1]]]], dtype=np.float32)\n",
        "pool = keras.layers.MaxPool2D(pool_size=(2,2), strides=1, padding='SAME')(image)\n",
        "print(pool.shape)\n",
        "print(pool.numpy())"
      ],
      "metadata": {
        "id": "4vDs2D7VEWVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "#mnist = keras.datasets.fashion_mnist\n",
        "#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "img = train_images[0]\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fORXFgg0Ei0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = img.reshape(-1,28,28,1)\n",
        "img = tf.convert_to_tensor(img)\n",
        "weight_init = keras.initializers.RandomNormal(stddev=0.01)\n",
        "conv2d = keras.layers.Conv2D(filters=5, kernel_size=3, strides=(2, 2), padding='SAME',\n",
        "                             kernel_initializer=weight_init)(img)\n",
        "print(conv2d.shape)\n",
        "feature_maps = np.swapaxes(conv2d, 0, 3)\n",
        "for i, feature_map in enumerate(feature_maps):\n",
        "    plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(14,14), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pvzivgHdEt95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pool = keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='SAME')(conv2d)\n",
        "print(pool.shape)\n",
        "\n",
        "feature_maps = np.swapaxes(pool, 0, 3)\n",
        "for i, feature_map in enumerate(feature_maps):\n",
        "    plt.subplot(1,5,i+1), plt.imshow(feature_map.reshape(7, 7), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cVnLT_t4EwXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Lab 11-1: Mnist cnn keras sequential eager**  \n",
        "&rarr; 기존과 달라진건 함수 CNN 정의만 달라졌다"
      ],
      "metadata": {
        "id": "Zdm3qSjEFJxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n"
      ],
      "metadata": {
        "id": "YDEMCpiRIF2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "tf.random.set_seed(777)\n",
        "cur_dir = os.getcwd()\n",
        "ckpt_dir_name = 'checkpoints'\n",
        "model_dir_name = 'minst_cnn_seq'\n",
        "\n",
        "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)"
      ],
      "metadata": {
        "id": "iTpnPCUTII3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n",
        "                buffer_size=100000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)"
      ],
      "metadata": {
        "id": "1xv5CUVxIWU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu, padding='SAME',\n",
        "                                  input_shape=(28, 28, 1)))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    model.add(keras.layers.Dense(10))\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZRc-K8eVEx7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
        "        y_pred=logits, y_true=labels, from_logits=True))\n",
        "    return loss\n",
        "\n",
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)\n",
        "\n",
        "def evaluate(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "checkpoint = tf.train.Checkpoint(cnn=model)"
      ],
      "metadata": {
        "id": "-LADM4wrIe1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, images, labels):\n",
        "    grads = grad(model, images, labels)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "print('Learning started. It takes sometime.')\n",
        "for epoch in range(training_epochs):\n",
        "    avg_loss = 0.\n",
        "    avg_train_acc = 0.\n",
        "    avg_test_acc = 0.\n",
        "    train_step = 0\n",
        "    test_step = 0\n",
        "\n",
        "    for images, labels in train_dataset:\n",
        "        train(model, images, labels)\n",
        "        #grads = grad(model, images, labels)\n",
        "        #optimizer.apply_gradients(zip(grads, model.variables))\n",
        "        loss = loss_fn(model, images, labels)\n",
        "        acc = evaluate(model, images, labels)\n",
        "        avg_loss = avg_loss + loss\n",
        "        avg_train_acc = avg_train_acc + acc\n",
        "        train_step += 1\n",
        "    avg_loss = avg_loss / train_step\n",
        "    avg_train_acc = avg_train_acc / train_step\n",
        "\n",
        "    for images, labels in test_dataset:\n",
        "        acc = evaluate(model, images, labels)\n",
        "        avg_test_acc = avg_test_acc + acc\n",
        "        test_step += 1\n",
        "    avg_test_acc = avg_test_acc / test_step\n",
        "\n",
        "    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss),\n",
        "          'train accuracy = ', '{:.4f}'.format(avg_train_acc),\n",
        "          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
        "\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "print('Learning Finished!')"
      ],
      "metadata": {
        "id": "PYiKyoF5IrRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Lab 11-2: Mnist model function eager**  \n",
        "&rarr; conv와 pooling layer를 직접 만들고 층을 쌓는 부분만 다르다"
      ],
      "metadata": {
        "id": "C4DxTJ_rG9P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    inputs = keras.Input(shape=(28, 28, 1))\n",
        "    conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(inputs)\n",
        "    pool1 = keras.layers.MaxPool2D(padding='SAME')(conv1)\n",
        "    conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(pool1)\n",
        "    pool2 = keras.layers.MaxPool2D(padding='SAME')(conv2)\n",
        "    conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(pool2)\n",
        "    pool3 = keras.layers.MaxPool2D(padding='SAME')(conv3)\n",
        "    pool3_flat = keras.layers.Flatten()(pool3)\n",
        "    dense4 = keras.layers.Dense(units=256, activation=tf.nn.relu)(pool3_flat)\n",
        "    drop4 = keras.layers.Dropout(rate=0.4)(dense4)\n",
        "    logits = keras.layers.Dense(units=10)(drop4)\n",
        "    return keras.Model(inputs=inputs, outputs=logits)"
      ],
      "metadata": {
        "id": "CoTGKIQAGe6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Lab 11-3: mnist cnn keras subclassing eager**  \n",
        "&rarr;  Model subscaling으로 class를 정의해서 사용한다"
      ],
      "metadata": {
        "id": "sm9X_O9NHxnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool1 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool2 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool3 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.pool3_flat = keras.layers.Flatten()\n",
        "        self.dense4 = keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
        "        self.drop4 = keras.layers.Dropout(rate=0.4)\n",
        "        self.dense5 = keras.layers.Dense(units=10)\n",
        "    def call(self, inputs, training=False):\n",
        "        net = self.conv1(inputs)\n",
        "        net = self.pool1(net)\n",
        "        net = self.conv2(net)\n",
        "        net = self.pool2(net)\n",
        "        net = self.conv3(net)\n",
        "        net = self.pool3(net)\n",
        "        net = self.pool3_flat(net)\n",
        "        net = self.dense4(net)\n",
        "        net = self.drop4(net)\n",
        "        net = self.dense5(net)\n",
        "        return net"
      ],
      "metadata": {
        "id": "4Y2YOoYXHTsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 11-4: mnist cnn keras ensemble eager**  \n",
        "&rarr; model을 여러개 만들어서 하나의 결과물을 출력해주는 과정  \n",
        "&rarr; modeling과 evluation 하는 부분만 바뀐다"
      ],
      "metadata": {
        "id": "v5pc0B3KKupW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool1 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool2 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.pool3 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.pool3_flat = keras.layers.Flatten()\n",
        "        self.dense4 = keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
        "        self.drop4 = keras.layers.Dropout(rate=0.4)\n",
        "        self.dense5 = keras.layers.Dense(units=10)\n",
        "    def call(self, inputs, training=False):\n",
        "        net = self.conv1(inputs)\n",
        "        net = self.pool1(net)\n",
        "        net = self.conv2(net)\n",
        "        net = self.pool2(net)\n",
        "        net = self.conv3(net)\n",
        "        net = self.pool3(net)\n",
        "        net = self.pool3_flat(net)\n",
        "        net = self.dense4(net)\n",
        "        net = self.drop4(net)\n",
        "        net = self.dense5(net)\n",
        "        return net\n",
        "models = []\n",
        "num_models = 3\n",
        "for m in range(num_models):\n",
        "    models.append(MNISTModel())\n",
        "\n"
      ],
      "metadata": {
        "id": "gvydqEQ_JEiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(models, images, labels):\n",
        "    predictions = np.zeros_like(labels)\n",
        "    for model in models:\n",
        "        logits = model(images, training=False)\n",
        "        predictions += logits\n",
        "    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "cO_6PmZ-LQvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 11-5: mnist cnn best keras eager**"
      ],
      "metadata": {
        "id": "BeBzGsY1Lsnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Data Argumentation**  \n",
        "- 주어진 data를 가지고 rotate, shift 등을 이용해서 data 개수를 늘리는 방법"
      ],
      "metadata": {
        "id": "4_OKkpZULyL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "def data_augmentation(images, labels):\n",
        "    aug_images = []\n",
        "    aug_labels = []\n",
        "\n",
        "    for x, y in zip(images, labels):\n",
        "        aug_images.append(x)\n",
        "        aug_labels.append(y)\n",
        "\n",
        "        bg_value = np.median(x)\n",
        "\n",
        "        for _ in range(4):\n",
        "            angle = np.random.randint(-15, 15, 1)\n",
        "            ###rotate\n",
        "            rot_img = ndimage.rotate(x, angle[0], reshape=False, cval=bg_value)\n",
        "\n",
        "            ###shift\n",
        "            shift = np.random.randint(-2, 2, 2)\n",
        "            shift_img = ndimage.shift(rot_img, shift, cval=bg_value)\n",
        "\n",
        "            aug_images.append(shift_img)\n",
        "            aug_labels.append(y)\n",
        "    aug_images = np.array(aug_images)\n",
        "    aug_labels = np.array(aug_labels)\n",
        "    return aug_images, aug_labels"
      ],
      "metadata": {
        "id": "fsj-aNMjLTpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Batch Normalization**  \n",
        "&rarr; dense와 그냥 conv layer를 나중에 합치는 형태로 진행하기 때문에 따로 class를 정의한다"
      ],
      "metadata": {
        "id": "4-awgpPgM3ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseBNRelu(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(DenseBNRelu, self).__init__()\n",
        "        self.dense = keras.layers.Dense(units=units, kernel_initializer='glorot_normal')\n",
        "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
        "    def call(self, inputs, training=False):\n",
        "        layer = self.dense(inputs)\n",
        "        layer = self.batchnorm(layer)\n",
        "        layer = tf.nn.relu(layer)\n",
        "        return layer"
      ],
      "metadata": {
        "id": "t5VqfsZDMXyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBNRelu(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size=3, strides=1, padding='SAME'):\n",
        "        super(ConvBNRelu, self).__init__()\n",
        "        self.conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n",
        "                                        padding=padding, kernel_initializer='glorot_normal')\n",
        "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
        "    def call(self, inputs, training=False):\n",
        "        layer = self.conv(inputs)\n",
        "        layer = self.batchnorm(layer)\n",
        "        layer = tf.nn.relu(layer)\n",
        "        return layer"
      ],
      "metadata": {
        "id": "AVg_f2ocNKKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.conv1 = ConvBNRelu(filters=32, kernel_size=[3, 3], padding='SAME')\n",
        "        self.pool1 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.conv2 = ConvBNRelu(filters=64, kernel_size=[3, 3], padding='SAME')\n",
        "        self.pool2 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.conv3 = ConvBNRelu(filters=128, kernel_size=[3, 3], padding='SAME')\n",
        "        self.pool3 = keras.layers.MaxPool2D(padding='SAME')\n",
        "        self.pool3_flat = keras.layers.Flatten()\n",
        "        self.dense4 = DenseBNRelu(units=256)\n",
        "        self.drop4 = keras.layers.Dropout(rate=0.4)\n",
        "        self.dense5 = keras.layers.Dense(units=10, kernel_initializer='glorot_normal')\n",
        "    def call(self, inputs, training=False):\n",
        "        net = self.conv1(inputs)\n",
        "        net = self.pool1(net)\n",
        "        net = self.conv2(net)\n",
        "        net = self.pool2(net)\n",
        "        net = self.conv3(net)\n",
        "        net = self.pool3(net)\n",
        "        net = self.pool3_flat(net)\n",
        "        net = self.dense4(net)\n",
        "        net = self.drop4(net)\n",
        "        net = self.dense5(net)\n",
        "        return net"
      ],
      "metadata": {
        "id": "zpxezEz0NNnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gGU_0bGOM8FE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}