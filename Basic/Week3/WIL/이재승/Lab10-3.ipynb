{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUQDM+2AqDNv4YLD6RxJHf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"JCaCIwy3DdtR","executionInfo":{"status":"ok","timestamp":1695389353502,"user_tz":-540,"elapsed":4898,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.datasets import mnist\n","from time import time\n","import os"]},{"cell_type":"code","source":["def load(model, checkpoint_dir):\n","    print(\" [*] Reading checkpoints...\")\n","\n","    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n","    if ckpt :\n","        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n","        checkpoint = tf.train.Checkpoint(dnn=model)\n","        checkpoint.restore(save_path=os.path.join(checkpoint_dir, ckpt_name))\n","        counter = int(ckpt_name.split('-')[1])\n","        print(\" [*] Success to read {}\".format(ckpt_name))\n","        return True, counter\n","    else:\n","        print(\" [*] Failed to find a checkpoint\")\n","        return False, 0\n","\n","def check_folder(dir):\n","    if not os.path.exists(dir):\n","        os.makedirs(dir)\n","    return dir"],"metadata":{"id":"Rq0-t8RAFDuq","executionInfo":{"status":"ok","timestamp":1695389353502,"user_tz":-540,"elapsed":7,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def load_mnist() :\n","    (train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n","    train_data = np.expand_dims(train_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n","    test_data = np.expand_dims(test_data, axis=-1) # [N, 28, 28] -> [N, 28, 28, 1]\n","\n","    train_data, test_data = normalize(train_data, test_data)\n","\n","    train_labels = to_categorical(train_labels, 10) # [N,] -> [N, 10]\n","    test_labels = to_categorical(test_labels, 10) # [N,] -> [N, 10]\n","\n","    return train_data, train_labels, test_data, test_labels\n","\n","def normalize(train_data, test_data):\n","    train_data = train_data.astype(np.float32) / 255.0\n","    test_data = test_data.astype(np.float32) / 255.0\n","\n","    return train_data, test_data"],"metadata":{"id":"AdCyqDD0FFHk","executionInfo":{"status":"ok","timestamp":1695389353503,"user_tz":-540,"elapsed":6,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# train에 dropout 사용시, training 변수를 True로 함.\n","def loss_fn(model, images, labels):\n","    logits = model(images, training=True)\n","    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels,\n","                                                                   from_logits=True))\n","    return loss\n","\n","# test 시에는 dropout 사용하지 않아야 하므로, training = False\n","def accuracy_fn(model, images, labels):\n","    logits = model(images, training=False)\n","    prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(labels, -1))\n","    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n","    return accuracy\n","\n","def grad(model, images, labels):\n","    with tf.GradientTape() as tape:\n","        loss = loss_fn(model, images, labels)\n","    return tape.gradient(loss, model.trainable_variables)"],"metadata":{"id":"TMQBxEBEFGUt","executionInfo":{"status":"ok","timestamp":1695389513973,"user_tz":-540,"elapsed":3,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def flatten() :\n","    return tf.keras.layers.Flatten()\n","\n","def dense(label_dim, weight_init) :\n","    return tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight_init)\n","\n","def relu() :\n","    return tf.keras.layers.Activation(tf.keras.activations.relu)\n","\n","# 여기에는 이 dropout 방법이 추가가 됨.\n","def dropout(rate) :\n","    return tf.keras.layers.Dropout(rate)"],"metadata":{"id":"3dn38uCXFHst","executionInfo":{"status":"ok","timestamp":1695389514964,"user_tz":-540,"elapsed":468,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def create_model_function(label_dim) :\n","    weight_init = tf.keras.initializers.glorot_uniform()\n","\n","    model = tf.keras.Sequential()\n","    model.add(flatten())\n","\n","    for i in range(4) :\n","        model.add(dense(512, weight_init))\n","        model.add(relu())\n","        model.add(dropout(rate=0.5))\n","\n","    model.add(dense(label_dim, weight_init))\n","\n","    return model"],"metadata":{"id":"F_Mrfm09FK_d","executionInfo":{"status":"ok","timestamp":1695389515270,"user_tz":-540,"elapsed":1,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["\"\"\" dataset \"\"\"\n","train_x, train_y, test_x, test_y = load_mnist()\n","\n","\"\"\" parameters \"\"\"\n","learning_rate = 0.001\n","batch_size = 128\n","\n","training_epochs = 1\n","training_iterations = len(train_x) // batch_size\n","\n","label_dim = 10\n","\n","train_flag = True\n","\n","\"\"\" Graph Input using Dataset API \"\"\"\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n","    shuffle(buffer_size=100000).\\\n","    prefetch(buffer_size=batch_size).\\\n","    batch(batch_size, drop_remainder=True)\n","    # 위와 같이 batch 안에 drop_remainder를 사용함.\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n","    shuffle(buffer_size=100000).\\\n","    prefetch(buffer_size=len(test_x)).\\\n","    batch(len(test_x))"],"metadata":{"id":"GC5Qj5lRFQR9","executionInfo":{"status":"ok","timestamp":1695389516908,"user_tz":-540,"elapsed":857,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["\"\"\" Model \"\"\"\n","network = create_model_function(label_dim)\n","\n","\"\"\" Training \"\"\"\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","\n","\"\"\" Writer \"\"\"\n","checkpoint_dir = 'checkpoints'\n","logs_dir = 'logs'\n","\n","model_dir = 'nn_dropout'\n","\n","checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n","check_folder(checkpoint_dir)\n","checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n","logs_dir = os.path.join(logs_dir, model_dir)"],"metadata":{"id":"8bnQJkcdFR5-","executionInfo":{"status":"ok","timestamp":1695389516908,"user_tz":-540,"elapsed":4,"user":{"displayName":"이재승","userId":"06759334452558132573"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["if train_flag :\n","\n","    checkpoint = tf.train.Checkpoint(dnn=network)\n","\n","    # create writer for tensorboard\n","    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n","    start_time = time()\n","\n","    # restore check-point if it exits\n","    could_load, checkpoint_counter = load(network, checkpoint_dir)\n","\n","    if could_load:\n","        start_epoch = (int)(checkpoint_counter / training_iterations)\n","        counter = checkpoint_counter\n","        print(\" [*] Load SUCCESS\")\n","    else:\n","        start_epoch = 0\n","        start_iteration = 0\n","        counter = 0\n","        print(\" [!] Load failed...\")\n","\n","    # train phase\n","    with summary_writer.as_default():  # for tensorboard\n","        for epoch in range(start_epoch, training_epochs):\n","            for idx, (train_input, train_label) in enumerate(train_dataset):\n","                grads = grad(network, train_input, train_label)\n","                optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n","\n","                train_loss = loss_fn(network, train_input, train_label)\n","                train_accuracy = accuracy_fn(network, train_input, train_label)\n","\n","                for test_input, test_label in test_dataset:\n","                    test_accuracy = accuracy_fn(network, test_input, test_label)\n","\n","                tf.summary.scalar(name='train_loss', data=train_loss, step=counter)\n","                tf.summary.scalar(name='train_accuracy', data=train_accuracy, step=counter)\n","                tf.summary.scalar(name='test_accuracy', data=test_accuracy, step=counter)\n","\n","                print(\n","                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n","                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n","                       test_accuracy))\n","                counter += 1\n","        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n","\n","# test phase\n","else :\n","    _, _ = load(network, checkpoint_dir)\n","    for test_input, test_label in test_dataset:\n","        test_accuracy = accuracy_fn(network, test_input, test_label)\n","\n","    print(\"test_Accuracy: %.4f\" % (test_accuracy))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBC6Xi5VFTpi","executionInfo":{"status":"ok","timestamp":1695389899515,"user_tz":-540,"elapsed":382274,"user":{"displayName":"이재승","userId":"06759334452558132573"}},"outputId":"c7b3cfb5-1012-4974-dac8-b5c1a70360e2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":[" [*] Reading checkpoints...\n"," [*] Failed to find a checkpoint\n"," [!] Load failed...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [ 0] [    0/  468] time: 1.7466, train_loss: 2.39581680, train_accuracy: 0.2031, test_Accuracy: 0.1459\n","Epoch: [ 0] [    1/  468] time: 2.3555, train_loss: 2.31659174, train_accuracy: 0.2500, test_Accuracy: 0.2326\n","Epoch: [ 0] [    2/  468] time: 3.0042, train_loss: 2.29823065, train_accuracy: 0.2969, test_Accuracy: 0.2618\n","Epoch: [ 0] [    3/  468] time: 3.7539, train_loss: 2.34569693, train_accuracy: 0.2422, test_Accuracy: 0.3156\n","Epoch: [ 0] [    4/  468] time: 5.2105, train_loss: 2.25628066, train_accuracy: 0.4453, test_Accuracy: 0.3635\n","Epoch: [ 0] [    5/  468] time: 6.5488, train_loss: 2.21024418, train_accuracy: 0.4062, test_Accuracy: 0.3695\n","Epoch: [ 0] [    6/  468] time: 7.1686, train_loss: 2.31476474, train_accuracy: 0.4453, test_Accuracy: 0.4123\n","Epoch: [ 0] [    7/  468] time: 7.7590, train_loss: 2.22241020, train_accuracy: 0.5547, test_Accuracy: 0.4475\n","Epoch: [ 0] [    8/  468] time: 8.3762, train_loss: 2.14425611, train_accuracy: 0.4375, test_Accuracy: 0.4773\n","Epoch: [ 0] [    9/  468] time: 8.9913, train_loss: 2.22660780, train_accuracy: 0.5547, test_Accuracy: 0.5275\n","Epoch: [ 0] [   10/  468] time: 9.5775, train_loss: 2.10979891, train_accuracy: 0.5234, test_Accuracy: 0.5908\n","Epoch: [ 0] [   11/  468] time: 10.2466, train_loss: 2.13520527, train_accuracy: 0.5938, test_Accuracy: 0.6370\n","Epoch: [ 0] [   12/  468] time: 11.1806, train_loss: 1.97310853, train_accuracy: 0.6875, test_Accuracy: 0.6354\n","Epoch: [ 0] [   13/  468] time: 11.8674, train_loss: 2.05475903, train_accuracy: 0.6016, test_Accuracy: 0.6227\n","Epoch: [ 0] [   14/  468] time: 12.4701, train_loss: 2.03420258, train_accuracy: 0.5625, test_Accuracy: 0.6061\n","Epoch: [ 0] [   15/  468] time: 13.2101, train_loss: 1.90571129, train_accuracy: 0.5781, test_Accuracy: 0.6167\n","Epoch: [ 0] [   16/  468] time: 14.1334, train_loss: 1.81456876, train_accuracy: 0.6641, test_Accuracy: 0.6203\n","Epoch: [ 0] [   17/  468] time: 14.7892, train_loss: 1.76547813, train_accuracy: 0.6875, test_Accuracy: 0.6085\n","Epoch: [ 0] [   18/  468] time: 15.4051, train_loss: 1.76686740, train_accuracy: 0.6328, test_Accuracy: 0.5969\n","Epoch: [ 0] [   19/  468] time: 16.0989, train_loss: 1.79102528, train_accuracy: 0.5625, test_Accuracy: 0.5996\n","Epoch: [ 0] [   20/  468] time: 17.5071, train_loss: 1.70371723, train_accuracy: 0.6172, test_Accuracy: 0.6086\n","Epoch: [ 0] [   21/  468] time: 18.9573, train_loss: 1.62112594, train_accuracy: 0.6562, test_Accuracy: 0.6213\n","Epoch: [ 0] [   22/  468] time: 19.7506, train_loss: 1.70007169, train_accuracy: 0.5781, test_Accuracy: 0.6385\n","Epoch: [ 0] [   23/  468] time: 20.5369, train_loss: 1.51217747, train_accuracy: 0.6797, test_Accuracy: 0.6497\n","Epoch: [ 0] [   24/  468] time: 21.3781, train_loss: 1.47972095, train_accuracy: 0.6016, test_Accuracy: 0.6593\n","Epoch: [ 0] [   25/  468] time: 21.9675, train_loss: 1.38169670, train_accuracy: 0.7266, test_Accuracy: 0.6707\n","Epoch: [ 0] [   26/  468] time: 22.5656, train_loss: 1.35716498, train_accuracy: 0.6641, test_Accuracy: 0.6919\n","Epoch: [ 0] [   27/  468] time: 23.3275, train_loss: 1.25208616, train_accuracy: 0.7812, test_Accuracy: 0.7200\n","Epoch: [ 0] [   28/  468] time: 24.1377, train_loss: 1.23807740, train_accuracy: 0.7344, test_Accuracy: 0.7358\n","Epoch: [ 0] [   29/  468] time: 25.0181, train_loss: 1.21515918, train_accuracy: 0.7422, test_Accuracy: 0.7491\n","Epoch: [ 0] [   30/  468] time: 25.6567, train_loss: 1.31736541, train_accuracy: 0.7422, test_Accuracy: 0.7595\n","Epoch: [ 0] [   31/  468] time: 27.1495, train_loss: 1.14793682, train_accuracy: 0.7812, test_Accuracy: 0.7618\n","Epoch: [ 0] [   32/  468] time: 27.7454, train_loss: 1.05500317, train_accuracy: 0.7500, test_Accuracy: 0.7598\n","Epoch: [ 0] [   33/  468] time: 28.3822, train_loss: 1.03680038, train_accuracy: 0.7812, test_Accuracy: 0.7612\n","Epoch: [ 0] [   34/  468] time: 29.0371, train_loss: 1.06747830, train_accuracy: 0.7578, test_Accuracy: 0.7640\n","Epoch: [ 0] [   35/  468] time: 29.9591, train_loss: 1.12824655, train_accuracy: 0.7188, test_Accuracy: 0.7642\n","Epoch: [ 0] [   36/  468] time: 31.0113, train_loss: 1.07882643, train_accuracy: 0.7031, test_Accuracy: 0.7614\n","Epoch: [ 0] [   37/  468] time: 32.5025, train_loss: 1.04439044, train_accuracy: 0.7734, test_Accuracy: 0.7583\n","Epoch: [ 0] [   38/  468] time: 33.1546, train_loss: 0.93045336, train_accuracy: 0.8047, test_Accuracy: 0.7590\n","Epoch: [ 0] [   39/  468] time: 33.7681, train_loss: 0.97303021, train_accuracy: 0.7578, test_Accuracy: 0.7724\n","Epoch: [ 0] [   40/  468] time: 34.4697, train_loss: 0.98826098, train_accuracy: 0.8047, test_Accuracy: 0.7839\n","Epoch: [ 0] [   41/  468] time: 35.9042, train_loss: 0.86878246, train_accuracy: 0.7891, test_Accuracy: 0.7988\n","Epoch: [ 0] [   42/  468] time: 36.4831, train_loss: 0.83169925, train_accuracy: 0.8281, test_Accuracy: 0.8095\n","Epoch: [ 0] [   43/  468] time: 37.1375, train_loss: 0.88502461, train_accuracy: 0.8281, test_Accuracy: 0.8171\n","Epoch: [ 0] [   44/  468] time: 37.8852, train_loss: 0.74876392, train_accuracy: 0.8281, test_Accuracy: 0.8184\n","Epoch: [ 0] [   45/  468] time: 38.4925, train_loss: 0.85321105, train_accuracy: 0.8594, test_Accuracy: 0.8139\n","Epoch: [ 0] [   46/  468] time: 39.1008, train_loss: 0.98317540, train_accuracy: 0.7969, test_Accuracy: 0.8119\n","Epoch: [ 0] [   47/  468] time: 39.8602, train_loss: 0.78241956, train_accuracy: 0.8438, test_Accuracy: 0.8085\n","Epoch: [ 0] [   48/  468] time: 40.7173, train_loss: 0.90846300, train_accuracy: 0.7734, test_Accuracy: 0.8127\n","Epoch: [ 0] [   49/  468] time: 42.1711, train_loss: 0.80436462, train_accuracy: 0.8203, test_Accuracy: 0.8224\n","Epoch: [ 0] [   50/  468] time: 43.6689, train_loss: 0.88908207, train_accuracy: 0.7969, test_Accuracy: 0.8309\n","Epoch: [ 0] [   51/  468] time: 44.6034, train_loss: 0.81874168, train_accuracy: 0.7891, test_Accuracy: 0.8387\n","Epoch: [ 0] [   52/  468] time: 45.3482, train_loss: 0.90020561, train_accuracy: 0.8359, test_Accuracy: 0.8437\n","Epoch: [ 0] [   53/  468] time: 46.0176, train_loss: 0.66927278, train_accuracy: 0.8750, test_Accuracy: 0.8435\n","Epoch: [ 0] [   54/  468] time: 46.9816, train_loss: 0.86089033, train_accuracy: 0.7891, test_Accuracy: 0.8444\n","Epoch: [ 0] [   55/  468] time: 47.6868, train_loss: 0.79635626, train_accuracy: 0.8438, test_Accuracy: 0.8489\n","Epoch: [ 0] [   56/  468] time: 48.2824, train_loss: 0.77915055, train_accuracy: 0.8516, test_Accuracy: 0.8544\n","Epoch: [ 0] [   57/  468] time: 48.8959, train_loss: 0.80023599, train_accuracy: 0.8281, test_Accuracy: 0.8623\n","Epoch: [ 0] [   58/  468] time: 49.6446, train_loss: 0.85823941, train_accuracy: 0.8594, test_Accuracy: 0.8645\n","Epoch: [ 0] [   59/  468] time: 50.2473, train_loss: 0.67236257, train_accuracy: 0.8438, test_Accuracy: 0.8657\n","Epoch: [ 0] [   60/  468] time: 50.8508, train_loss: 0.74965298, train_accuracy: 0.8203, test_Accuracy: 0.8655\n","Epoch: [ 0] [   61/  468] time: 51.4539, train_loss: 0.65519643, train_accuracy: 0.8828, test_Accuracy: 0.8655\n","Epoch: [ 0] [   62/  468] time: 52.0486, train_loss: 0.59594291, train_accuracy: 0.9062, test_Accuracy: 0.8647\n","Epoch: [ 0] [   63/  468] time: 53.1019, train_loss: 0.53023869, train_accuracy: 0.8750, test_Accuracy: 0.8678\n","Epoch: [ 0] [   64/  468] time: 53.8405, train_loss: 0.74359101, train_accuracy: 0.8281, test_Accuracy: 0.8667\n","Epoch: [ 0] [   65/  468] time: 55.3572, train_loss: 0.52447647, train_accuracy: 0.8906, test_Accuracy: 0.8719\n","Epoch: [ 0] [   66/  468] time: 57.6903, train_loss: 0.66141701, train_accuracy: 0.8672, test_Accuracy: 0.8764\n","Epoch: [ 0] [   67/  468] time: 58.2825, train_loss: 0.58557850, train_accuracy: 0.8516, test_Accuracy: 0.8803\n","Epoch: [ 0] [   68/  468] time: 58.9004, train_loss: 0.57825691, train_accuracy: 0.8906, test_Accuracy: 0.8844\n","Epoch: [ 0] [   69/  468] time: 59.5011, train_loss: 0.64909422, train_accuracy: 0.9062, test_Accuracy: 0.8866\n","Epoch: [ 0] [   70/  468] time: 60.1034, train_loss: 0.55365294, train_accuracy: 0.8438, test_Accuracy: 0.8856\n","Epoch: [ 0] [   71/  468] time: 60.6947, train_loss: 0.52314425, train_accuracy: 0.8906, test_Accuracy: 0.8857\n","Epoch: [ 0] [   72/  468] time: 61.2841, train_loss: 0.56339872, train_accuracy: 0.9219, test_Accuracy: 0.8845\n","Epoch: [ 0] [   73/  468] time: 62.0265, train_loss: 0.68316478, train_accuracy: 0.8438, test_Accuracy: 0.8860\n","Epoch: [ 0] [   74/  468] time: 62.6359, train_loss: 0.74061161, train_accuracy: 0.8750, test_Accuracy: 0.8894\n","Epoch: [ 0] [   75/  468] time: 63.3895, train_loss: 0.57052827, train_accuracy: 0.8984, test_Accuracy: 0.8913\n","Epoch: [ 0] [   76/  468] time: 64.1434, train_loss: 0.58652866, train_accuracy: 0.9062, test_Accuracy: 0.8888\n","Epoch: [ 0] [   77/  468] time: 64.7485, train_loss: 0.56351924, train_accuracy: 0.9297, test_Accuracy: 0.8853\n","Epoch: [ 0] [   78/  468] time: 65.3461, train_loss: 0.52368951, train_accuracy: 0.9062, test_Accuracy: 0.8848\n","Epoch: [ 0] [   79/  468] time: 65.9368, train_loss: 0.49429813, train_accuracy: 0.9062, test_Accuracy: 0.8858\n","Epoch: [ 0] [   80/  468] time: 66.5381, train_loss: 0.72348595, train_accuracy: 0.8594, test_Accuracy: 0.8879\n","Epoch: [ 0] [   81/  468] time: 67.2884, train_loss: 0.75153887, train_accuracy: 0.8438, test_Accuracy: 0.8886\n","Epoch: [ 0] [   82/  468] time: 68.1606, train_loss: 0.57951814, train_accuracy: 0.8906, test_Accuracy: 0.8900\n","Epoch: [ 0] [   83/  468] time: 69.6213, train_loss: 0.54383451, train_accuracy: 0.8984, test_Accuracy: 0.8936\n","Epoch: [ 0] [   84/  468] time: 70.6323, train_loss: 0.64355087, train_accuracy: 0.8750, test_Accuracy: 0.8977\n","Epoch: [ 0] [   85/  468] time: 71.4527, train_loss: 0.73309368, train_accuracy: 0.8750, test_Accuracy: 0.8991\n","Epoch: [ 0] [   86/  468] time: 72.7112, train_loss: 0.49561590, train_accuracy: 0.9219, test_Accuracy: 0.8991\n","Epoch: [ 0] [   87/  468] time: 73.6178, train_loss: 0.52577174, train_accuracy: 0.9375, test_Accuracy: 0.9004\n","Epoch: [ 0] [   88/  468] time: 74.4427, train_loss: 0.54851758, train_accuracy: 0.8984, test_Accuracy: 0.9020\n","Epoch: [ 0] [   89/  468] time: 75.2299, train_loss: 0.63290828, train_accuracy: 0.8594, test_Accuracy: 0.9021\n","Epoch: [ 0] [   90/  468] time: 76.3392, train_loss: 0.59203953, train_accuracy: 0.8906, test_Accuracy: 0.9016\n","Epoch: [ 0] [   91/  468] time: 77.3577, train_loss: 0.44167325, train_accuracy: 0.9062, test_Accuracy: 0.9027\n","Epoch: [ 0] [   92/  468] time: 78.5567, train_loss: 0.63799429, train_accuracy: 0.8828, test_Accuracy: 0.9020\n","Epoch: [ 0] [   93/  468] time: 79.6155, train_loss: 0.45846072, train_accuracy: 0.8984, test_Accuracy: 0.9041\n","Epoch: [ 0] [   94/  468] time: 80.3041, train_loss: 0.59547782, train_accuracy: 0.8984, test_Accuracy: 0.9061\n","Epoch: [ 0] [   95/  468] time: 81.7176, train_loss: 0.53341889, train_accuracy: 0.9141, test_Accuracy: 0.9069\n","Epoch: [ 0] [   96/  468] time: 82.8987, train_loss: 0.52832603, train_accuracy: 0.8672, test_Accuracy: 0.9063\n","Epoch: [ 0] [   97/  468] time: 84.3734, train_loss: 0.60720992, train_accuracy: 0.8750, test_Accuracy: 0.9057\n","Epoch: [ 0] [   98/  468] time: 85.1624, train_loss: 0.56053466, train_accuracy: 0.9141, test_Accuracy: 0.9071\n","Epoch: [ 0] [   99/  468] time: 85.7621, train_loss: 0.58463198, train_accuracy: 0.9062, test_Accuracy: 0.9066\n","Epoch: [ 0] [  100/  468] time: 86.3801, train_loss: 0.57027930, train_accuracy: 0.8594, test_Accuracy: 0.9088\n","Epoch: [ 0] [  101/  468] time: 86.9727, train_loss: 0.41451827, train_accuracy: 0.9141, test_Accuracy: 0.9090\n","Epoch: [ 0] [  102/  468] time: 87.5995, train_loss: 0.40240479, train_accuracy: 0.9297, test_Accuracy: 0.9099\n","Epoch: [ 0] [  103/  468] time: 88.1752, train_loss: 0.45551443, train_accuracy: 0.8906, test_Accuracy: 0.9082\n","Epoch: [ 0] [  104/  468] time: 88.9157, train_loss: 0.44429144, train_accuracy: 0.8828, test_Accuracy: 0.9072\n","Epoch: [ 0] [  105/  468] time: 89.5064, train_loss: 0.54922497, train_accuracy: 0.8984, test_Accuracy: 0.9075\n","Epoch: [ 0] [  106/  468] time: 90.2518, train_loss: 0.37770653, train_accuracy: 0.8984, test_Accuracy: 0.9082\n","Epoch: [ 0] [  107/  468] time: 90.9970, train_loss: 0.48789641, train_accuracy: 0.9141, test_Accuracy: 0.9107\n","Epoch: [ 0] [  108/  468] time: 91.5924, train_loss: 0.47187787, train_accuracy: 0.9062, test_Accuracy: 0.9098\n","Epoch: [ 0] [  109/  468] time: 92.3338, train_loss: 0.41287786, train_accuracy: 0.9375, test_Accuracy: 0.9104\n","Epoch: [ 0] [  110/  468] time: 92.9498, train_loss: 0.35377711, train_accuracy: 0.9375, test_Accuracy: 0.9072\n","Epoch: [ 0] [  111/  468] time: 94.3379, train_loss: 0.47226486, train_accuracy: 0.9141, test_Accuracy: 0.9036\n","Epoch: [ 0] [  112/  468] time: 95.7889, train_loss: 0.70018280, train_accuracy: 0.8281, test_Accuracy: 0.9045\n","Epoch: [ 0] [  113/  468] time: 96.4248, train_loss: 0.44911933, train_accuracy: 0.9062, test_Accuracy: 0.9051\n","Epoch: [ 0] [  114/  468] time: 97.1724, train_loss: 0.40614018, train_accuracy: 0.9062, test_Accuracy: 0.9077\n","Epoch: [ 0] [  115/  468] time: 97.7615, train_loss: 0.45360401, train_accuracy: 0.8906, test_Accuracy: 0.9090\n","Epoch: [ 0] [  116/  468] time: 98.3608, train_loss: 0.58811796, train_accuracy: 0.8984, test_Accuracy: 0.9100\n","Epoch: [ 0] [  117/  468] time: 98.9595, train_loss: 0.44014353, train_accuracy: 0.9297, test_Accuracy: 0.9123\n","Epoch: [ 0] [  118/  468] time: 99.5715, train_loss: 0.45286480, train_accuracy: 0.9219, test_Accuracy: 0.9154\n","Epoch: [ 0] [  119/  468] time: 100.3169, train_loss: 0.37183762, train_accuracy: 0.9219, test_Accuracy: 0.9185\n","Epoch: [ 0] [  120/  468] time: 100.9088, train_loss: 0.38107812, train_accuracy: 0.9297, test_Accuracy: 0.9191\n","Epoch: [ 0] [  121/  468] time: 101.5152, train_loss: 0.51493347, train_accuracy: 0.8984, test_Accuracy: 0.9182\n","Epoch: [ 0] [  122/  468] time: 102.2582, train_loss: 0.62688929, train_accuracy: 0.8828, test_Accuracy: 0.9188\n","Epoch: [ 0] [  123/  468] time: 102.9994, train_loss: 0.57221174, train_accuracy: 0.8906, test_Accuracy: 0.9202\n","Epoch: [ 0] [  124/  468] time: 103.6069, train_loss: 0.36708122, train_accuracy: 0.9219, test_Accuracy: 0.9212\n","Epoch: [ 0] [  125/  468] time: 104.2177, train_loss: 0.31710666, train_accuracy: 0.9375, test_Accuracy: 0.9221\n","Epoch: [ 0] [  126/  468] time: 104.8195, train_loss: 0.35131952, train_accuracy: 0.9531, test_Accuracy: 0.9240\n","Epoch: [ 0] [  127/  468] time: 105.4197, train_loss: 0.34113598, train_accuracy: 0.9453, test_Accuracy: 0.9247\n","Epoch: [ 0] [  128/  468] time: 106.8354, train_loss: 0.39663613, train_accuracy: 0.9297, test_Accuracy: 0.9246\n","Epoch: [ 0] [  129/  468] time: 107.8536, train_loss: 0.31734896, train_accuracy: 0.9375, test_Accuracy: 0.9240\n","Epoch: [ 0] [  130/  468] time: 108.4462, train_loss: 0.49500638, train_accuracy: 0.8906, test_Accuracy: 0.9233\n","Epoch: [ 0] [  131/  468] time: 109.0386, train_loss: 0.36990100, train_accuracy: 0.9453, test_Accuracy: 0.9215\n","Epoch: [ 0] [  132/  468] time: 109.7772, train_loss: 0.46901709, train_accuracy: 0.9141, test_Accuracy: 0.9212\n","Epoch: [ 0] [  133/  468] time: 110.3794, train_loss: 0.39422047, train_accuracy: 0.8672, test_Accuracy: 0.9225\n","Epoch: [ 0] [  134/  468] time: 111.1313, train_loss: 0.43705106, train_accuracy: 0.9062, test_Accuracy: 0.9247\n","Epoch: [ 0] [  135/  468] time: 111.7309, train_loss: 0.33506984, train_accuracy: 0.9453, test_Accuracy: 0.9263\n","Epoch: [ 0] [  136/  468] time: 112.3349, train_loss: 0.33816260, train_accuracy: 0.9609, test_Accuracy: 0.9282\n","Epoch: [ 0] [  137/  468] time: 112.8964, train_loss: 0.51982599, train_accuracy: 0.9062, test_Accuracy: 0.9256\n","Epoch: [ 0] [  138/  468] time: 113.4763, train_loss: 0.39728844, train_accuracy: 0.9219, test_Accuracy: 0.9234\n","Epoch: [ 0] [  139/  468] time: 114.0715, train_loss: 0.36864233, train_accuracy: 0.9297, test_Accuracy: 0.9193\n","Epoch: [ 0] [  140/  468] time: 114.8128, train_loss: 0.32650283, train_accuracy: 0.9844, test_Accuracy: 0.9187\n","Epoch: [ 0] [  141/  468] time: 115.3916, train_loss: 0.40000173, train_accuracy: 0.8984, test_Accuracy: 0.9174\n","Epoch: [ 0] [  142/  468] time: 115.9725, train_loss: 0.47086349, train_accuracy: 0.9219, test_Accuracy: 0.9219\n","Epoch: [ 0] [  143/  468] time: 116.5653, train_loss: 0.31027257, train_accuracy: 0.9375, test_Accuracy: 0.9226\n","Epoch: [ 0] [  144/  468] time: 117.1669, train_loss: 0.35557777, train_accuracy: 0.9219, test_Accuracy: 0.9220\n","Epoch: [ 0] [  145/  468] time: 117.7668, train_loss: 0.41271096, train_accuracy: 0.8984, test_Accuracy: 0.9219\n","Epoch: [ 0] [  146/  468] time: 119.1485, train_loss: 0.31759083, train_accuracy: 0.9297, test_Accuracy: 0.9210\n","Epoch: [ 0] [  147/  468] time: 120.6078, train_loss: 0.36635035, train_accuracy: 0.9297, test_Accuracy: 0.9212\n","Epoch: [ 0] [  148/  468] time: 121.3686, train_loss: 0.37813669, train_accuracy: 0.9453, test_Accuracy: 0.9226\n","Epoch: [ 0] [  149/  468] time: 121.9711, train_loss: 0.57642919, train_accuracy: 0.9062, test_Accuracy: 0.9242\n","Epoch: [ 0] [  150/  468] time: 122.5541, train_loss: 0.31445041, train_accuracy: 0.9375, test_Accuracy: 0.9253\n","Epoch: [ 0] [  151/  468] time: 123.1508, train_loss: 0.42465508, train_accuracy: 0.9375, test_Accuracy: 0.9272\n","Epoch: [ 0] [  152/  468] time: 123.7662, train_loss: 0.45763603, train_accuracy: 0.9219, test_Accuracy: 0.9280\n","Epoch: [ 0] [  153/  468] time: 124.3756, train_loss: 0.42062619, train_accuracy: 0.9062, test_Accuracy: 0.9288\n","Epoch: [ 0] [  154/  468] time: 124.9725, train_loss: 0.40961558, train_accuracy: 0.9062, test_Accuracy: 0.9303\n","Epoch: [ 0] [  155/  468] time: 125.5626, train_loss: 0.42581478, train_accuracy: 0.9453, test_Accuracy: 0.9293\n","Epoch: [ 0] [  156/  468] time: 126.1725, train_loss: 0.33618343, train_accuracy: 0.9219, test_Accuracy: 0.9281\n","Epoch: [ 0] [  157/  468] time: 126.9114, train_loss: 0.52778029, train_accuracy: 0.9375, test_Accuracy: 0.9298\n","Epoch: [ 0] [  158/  468] time: 127.5065, train_loss: 0.47815087, train_accuracy: 0.9141, test_Accuracy: 0.9305\n","Epoch: [ 0] [  159/  468] time: 128.1134, train_loss: 0.33797109, train_accuracy: 0.9141, test_Accuracy: 0.9306\n","Epoch: [ 0] [  160/  468] time: 128.7176, train_loss: 0.36359966, train_accuracy: 0.9062, test_Accuracy: 0.9311\n","Epoch: [ 0] [  161/  468] time: 129.3116, train_loss: 0.27488554, train_accuracy: 0.9609, test_Accuracy: 0.9305\n","Epoch: [ 0] [  162/  468] time: 129.9011, train_loss: 0.49910563, train_accuracy: 0.9219, test_Accuracy: 0.9300\n","Epoch: [ 0] [  163/  468] time: 130.7067, train_loss: 0.50853205, train_accuracy: 0.9062, test_Accuracy: 0.9292\n","Epoch: [ 0] [  165/  468] time: 133.1361, train_loss: 0.40863487, train_accuracy: 0.9141, test_Accuracy: 0.9286\n","Epoch: [ 0] [  166/  468] time: 133.7216, train_loss: 0.50310248, train_accuracy: 0.8906, test_Accuracy: 0.9305\n","Epoch: [ 0] [  167/  468] time: 134.4614, train_loss: 0.50443614, train_accuracy: 0.9375, test_Accuracy: 0.9323\n","Epoch: [ 0] [  168/  468] time: 135.0536, train_loss: 0.32815480, train_accuracy: 0.9531, test_Accuracy: 0.9320\n","Epoch: [ 0] [  169/  468] time: 135.6604, train_loss: 0.26345584, train_accuracy: 0.9688, test_Accuracy: 0.9308\n","Epoch: [ 0] [  170/  468] time: 136.2691, train_loss: 0.23018304, train_accuracy: 0.9297, test_Accuracy: 0.9291\n","Epoch: [ 0] [  171/  468] time: 136.8819, train_loss: 0.34057122, train_accuracy: 0.9219, test_Accuracy: 0.9265\n","Epoch: [ 0] [  172/  468] time: 137.6235, train_loss: 0.39363071, train_accuracy: 0.9531, test_Accuracy: 0.9251\n","Epoch: [ 0] [  173/  468] time: 138.2080, train_loss: 0.36682752, train_accuracy: 0.9297, test_Accuracy: 0.9240\n","Epoch: [ 0] [  174/  468] time: 138.9579, train_loss: 0.29739287, train_accuracy: 0.9453, test_Accuracy: 0.9251\n","Epoch: [ 0] [  175/  468] time: 139.5815, train_loss: 0.46455267, train_accuracy: 0.8750, test_Accuracy: 0.9288\n","Epoch: [ 0] [  176/  468] time: 140.1799, train_loss: 0.28311238, train_accuracy: 0.9688, test_Accuracy: 0.9291\n","Epoch: [ 0] [  177/  468] time: 140.7833, train_loss: 0.28568140, train_accuracy: 0.9375, test_Accuracy: 0.9296\n","Epoch: [ 0] [  178/  468] time: 141.3738, train_loss: 0.48112926, train_accuracy: 0.9141, test_Accuracy: 0.9296\n","Epoch: [ 0] [  179/  468] time: 141.9716, train_loss: 0.29169983, train_accuracy: 0.9531, test_Accuracy: 0.9281\n","Epoch: [ 0] [  180/  468] time: 142.6027, train_loss: 0.33669955, train_accuracy: 0.9141, test_Accuracy: 0.9263\n","Epoch: [ 0] [  181/  468] time: 143.3530, train_loss: 0.20143846, train_accuracy: 0.9766, test_Accuracy: 0.9246\n","Epoch: [ 0] [  182/  468] time: 144.8181, train_loss: 0.47979966, train_accuracy: 0.8828, test_Accuracy: 0.9267\n","Epoch: [ 0] [  183/  468] time: 145.6094, train_loss: 0.35490599, train_accuracy: 0.9062, test_Accuracy: 0.9293\n","Epoch: [ 0] [  184/  468] time: 146.2018, train_loss: 0.32240742, train_accuracy: 0.9297, test_Accuracy: 0.9309\n","Epoch: [ 0] [  185/  468] time: 146.7980, train_loss: 0.34014937, train_accuracy: 0.9297, test_Accuracy: 0.9330\n","Epoch: [ 0] [  186/  468] time: 147.5435, train_loss: 0.27243918, train_accuracy: 0.9609, test_Accuracy: 0.9341\n","Epoch: [ 0] [  187/  468] time: 148.1138, train_loss: 0.28321576, train_accuracy: 0.9531, test_Accuracy: 0.9331\n","Epoch: [ 0] [  188/  468] time: 148.8565, train_loss: 0.26382291, train_accuracy: 0.9297, test_Accuracy: 0.9341\n","Epoch: [ 0] [  189/  468] time: 149.4568, train_loss: 0.20685180, train_accuracy: 0.9688, test_Accuracy: 0.9333\n","Epoch: [ 0] [  190/  468] time: 150.2074, train_loss: 0.40334514, train_accuracy: 0.9141, test_Accuracy: 0.9331\n","Epoch: [ 0] [  191/  468] time: 150.8269, train_loss: 0.43786347, train_accuracy: 0.8828, test_Accuracy: 0.9340\n","Epoch: [ 0] [  192/  468] time: 151.5721, train_loss: 0.32712185, train_accuracy: 0.9297, test_Accuracy: 0.9343\n","Epoch: [ 0] [  193/  468] time: 152.1841, train_loss: 0.39701530, train_accuracy: 0.9453, test_Accuracy: 0.9365\n","Epoch: [ 0] [  194/  468] time: 152.7791, train_loss: 0.31441528, train_accuracy: 0.9453, test_Accuracy: 0.9367\n","Epoch: [ 0] [  195/  468] time: 153.3684, train_loss: 0.34180647, train_accuracy: 0.9219, test_Accuracy: 0.9372\n","Epoch: [ 0] [  196/  468] time: 153.9730, train_loss: 0.18730825, train_accuracy: 0.9766, test_Accuracy: 0.9377\n","Epoch: [ 0] [  197/  468] time: 154.5812, train_loss: 0.32690489, train_accuracy: 0.9297, test_Accuracy: 0.9369\n","Epoch: [ 0] [  198/  468] time: 155.2107, train_loss: 0.23738745, train_accuracy: 0.9453, test_Accuracy: 0.9363\n","Epoch: [ 0] [  199/  468] time: 156.5971, train_loss: 0.25935158, train_accuracy: 0.9531, test_Accuracy: 0.9356\n","Epoch: [ 0] [  200/  468] time: 157.6091, train_loss: 0.50779116, train_accuracy: 0.9141, test_Accuracy: 0.9359\n","Epoch: [ 0] [  201/  468] time: 158.2555, train_loss: 0.29256061, train_accuracy: 0.9453, test_Accuracy: 0.9363\n","Epoch: [ 0] [  202/  468] time: 158.8527, train_loss: 0.28942293, train_accuracy: 0.9453, test_Accuracy: 0.9365\n","Epoch: [ 0] [  203/  468] time: 159.4678, train_loss: 0.33833829, train_accuracy: 0.9219, test_Accuracy: 0.9366\n","Epoch: [ 0] [  204/  468] time: 160.0772, train_loss: 0.38891590, train_accuracy: 0.9453, test_Accuracy: 0.9359\n","Epoch: [ 0] [  205/  468] time: 160.6532, train_loss: 0.53167760, train_accuracy: 0.8984, test_Accuracy: 0.9360\n","Epoch: [ 0] [  206/  468] time: 161.2357, train_loss: 0.26316518, train_accuracy: 0.9531, test_Accuracy: 0.9368\n","Epoch: [ 0] [  207/  468] time: 161.8385, train_loss: 0.30384511, train_accuracy: 0.9219, test_Accuracy: 0.9370\n","Epoch: [ 0] [  208/  468] time: 162.4499, train_loss: 0.25333983, train_accuracy: 0.9688, test_Accuracy: 0.9360\n","Epoch: [ 0] [  209/  468] time: 163.0383, train_loss: 0.35096011, train_accuracy: 0.9453, test_Accuracy: 0.9354\n","Epoch: [ 0] [  210/  468] time: 163.6390, train_loss: 0.24083704, train_accuracy: 0.9453, test_Accuracy: 0.9339\n","Epoch: [ 0] [  211/  468] time: 164.3864, train_loss: 0.26932782, train_accuracy: 0.9453, test_Accuracy: 0.9343\n","Epoch: [ 0] [  212/  468] time: 164.9898, train_loss: 0.28805572, train_accuracy: 0.9609, test_Accuracy: 0.9344\n","Epoch: [ 0] [  213/  468] time: 165.7409, train_loss: 0.35407770, train_accuracy: 0.9375, test_Accuracy: 0.9343\n","Epoch: [ 0] [  214/  468] time: 166.3312, train_loss: 0.31509250, train_accuracy: 0.9453, test_Accuracy: 0.9360\n","Epoch: [ 0] [  215/  468] time: 166.9384, train_loss: 0.32495064, train_accuracy: 0.9453, test_Accuracy: 0.9366\n","Epoch: [ 0] [  216/  468] time: 167.5344, train_loss: 0.30733591, train_accuracy: 0.9531, test_Accuracy: 0.9393\n","Epoch: [ 0] [  217/  468] time: 168.9172, train_loss: 0.24839172, train_accuracy: 0.9531, test_Accuracy: 0.9392\n","Epoch: [ 0] [  218/  468] time: 170.3537, train_loss: 0.41319126, train_accuracy: 0.9375, test_Accuracy: 0.9406\n","Epoch: [ 0] [  219/  468] time: 170.9579, train_loss: 0.23464468, train_accuracy: 0.9453, test_Accuracy: 0.9399\n","Epoch: [ 0] [  220/  468] time: 171.5544, train_loss: 0.31332237, train_accuracy: 0.9609, test_Accuracy: 0.9408\n","Epoch: [ 0] [  221/  468] time: 172.1412, train_loss: 0.27068627, train_accuracy: 0.9531, test_Accuracy: 0.9411\n","Epoch: [ 0] [  222/  468] time: 172.7689, train_loss: 0.32330406, train_accuracy: 0.9609, test_Accuracy: 0.9415\n","Epoch: [ 0] [  223/  468] time: 173.3589, train_loss: 0.33885133, train_accuracy: 0.9219, test_Accuracy: 0.9417\n","Epoch: [ 0] [  224/  468] time: 173.9412, train_loss: 0.34719470, train_accuracy: 0.9297, test_Accuracy: 0.9394\n","Epoch: [ 0] [  225/  468] time: 174.5412, train_loss: 0.26139534, train_accuracy: 0.9453, test_Accuracy: 0.9391\n","Epoch: [ 0] [  226/  468] time: 175.1309, train_loss: 0.45540911, train_accuracy: 0.9141, test_Accuracy: 0.9400\n","Epoch: [ 0] [  227/  468] time: 175.7089, train_loss: 0.32095593, train_accuracy: 0.9375, test_Accuracy: 0.9407\n","Epoch: [ 0] [  228/  468] time: 176.3024, train_loss: 0.35478875, train_accuracy: 0.9141, test_Accuracy: 0.9402\n","Epoch: [ 0] [  229/  468] time: 176.9226, train_loss: 0.38189065, train_accuracy: 0.9219, test_Accuracy: 0.9406\n","Epoch: [ 0] [  230/  468] time: 177.4987, train_loss: 0.32093012, train_accuracy: 0.9688, test_Accuracy: 0.9403\n","Epoch: [ 0] [  231/  468] time: 178.0950, train_loss: 0.27685341, train_accuracy: 0.9766, test_Accuracy: 0.9410\n","Epoch: [ 0] [  232/  468] time: 178.6907, train_loss: 0.24974164, train_accuracy: 0.9453, test_Accuracy: 0.9427\n","Epoch: [ 0] [  233/  468] time: 179.4371, train_loss: 0.29606977, train_accuracy: 0.9844, test_Accuracy: 0.9444\n","Epoch: [ 0] [  234/  468] time: 180.0494, train_loss: 0.42016441, train_accuracy: 0.9219, test_Accuracy: 0.9456\n","Epoch: [ 0] [  235/  468] time: 181.5017, train_loss: 0.36865783, train_accuracy: 0.9531, test_Accuracy: 0.9454\n","Epoch: [ 0] [  236/  468] time: 182.4573, train_loss: 0.35617083, train_accuracy: 0.9531, test_Accuracy: 0.9453\n","Epoch: [ 0] [  237/  468] time: 183.8614, train_loss: 0.18793952, train_accuracy: 0.9531, test_Accuracy: 0.9461\n","Epoch: [ 0] [  238/  468] time: 184.9161, train_loss: 0.17078573, train_accuracy: 0.9844, test_Accuracy: 0.9466\n","Epoch: [ 0] [  239/  468] time: 185.5245, train_loss: 0.40091372, train_accuracy: 0.9453, test_Accuracy: 0.9462\n","Epoch: [ 0] [  240/  468] time: 186.1371, train_loss: 0.34538400, train_accuracy: 0.9453, test_Accuracy: 0.9457\n","Epoch: [ 0] [  241/  468] time: 186.7345, train_loss: 0.25415689, train_accuracy: 0.9766, test_Accuracy: 0.9455\n","Epoch: [ 0] [  242/  468] time: 187.3410, train_loss: 0.34161276, train_accuracy: 0.9453, test_Accuracy: 0.9452\n","Epoch: [ 0] [  243/  468] time: 187.9430, train_loss: 0.38180360, train_accuracy: 0.9375, test_Accuracy: 0.9464\n","Epoch: [ 0] [  244/  468] time: 188.5473, train_loss: 0.25331709, train_accuracy: 0.9531, test_Accuracy: 0.9468\n","Epoch: [ 0] [  245/  468] time: 189.2863, train_loss: 0.28009480, train_accuracy: 0.9219, test_Accuracy: 0.9475\n","Epoch: [ 0] [  246/  468] time: 189.8900, train_loss: 0.19505909, train_accuracy: 0.9609, test_Accuracy: 0.9471\n","Epoch: [ 0] [  247/  468] time: 190.4779, train_loss: 0.28121185, train_accuracy: 0.9375, test_Accuracy: 0.9464\n","Epoch: [ 0] [  248/  468] time: 191.0897, train_loss: 0.28299662, train_accuracy: 0.9688, test_Accuracy: 0.9462\n","Epoch: [ 0] [  249/  468] time: 191.6656, train_loss: 0.38458398, train_accuracy: 0.9375, test_Accuracy: 0.9462\n","Epoch: [ 0] [  250/  468] time: 192.2631, train_loss: 0.27402034, train_accuracy: 0.9531, test_Accuracy: 0.9460\n","Epoch: [ 0] [  251/  468] time: 193.6515, train_loss: 0.15867531, train_accuracy: 0.9688, test_Accuracy: 0.9464\n","Epoch: [ 0] [  252/  468] time: 195.0929, train_loss: 0.21750562, train_accuracy: 0.9609, test_Accuracy: 0.9460\n","Epoch: [ 0] [  253/  468] time: 195.8342, train_loss: 0.30756465, train_accuracy: 0.9453, test_Accuracy: 0.9465\n","Epoch: [ 0] [  254/  468] time: 196.5870, train_loss: 0.23839867, train_accuracy: 0.9375, test_Accuracy: 0.9464\n","Epoch: [ 0] [  255/  468] time: 197.2296, train_loss: 0.28773457, train_accuracy: 0.9688, test_Accuracy: 0.9465\n","Epoch: [ 0] [  256/  468] time: 197.9763, train_loss: 0.35534346, train_accuracy: 0.9297, test_Accuracy: 0.9444\n","Epoch: [ 0] [  257/  468] time: 198.7399, train_loss: 0.51113063, train_accuracy: 0.8906, test_Accuracy: 0.9438\n","Epoch: [ 0] [  258/  468] time: 199.3229, train_loss: 0.26142842, train_accuracy: 0.9531, test_Accuracy: 0.9427\n","Epoch: [ 0] [  259/  468] time: 199.9093, train_loss: 0.27436838, train_accuracy: 0.9062, test_Accuracy: 0.9426\n","Epoch: [ 0] [  260/  468] time: 200.4928, train_loss: 0.32844317, train_accuracy: 0.9609, test_Accuracy: 0.9420\n","Epoch: [ 0] [  261/  468] time: 201.1053, train_loss: 0.39425939, train_accuracy: 0.9141, test_Accuracy: 0.9415\n","Epoch: [ 0] [  262/  468] time: 201.6939, train_loss: 0.30490249, train_accuracy: 0.9375, test_Accuracy: 0.9419\n","Epoch: [ 0] [  263/  468] time: 202.3114, train_loss: 0.16882989, train_accuracy: 0.9922, test_Accuracy: 0.9427\n","Epoch: [ 0] [  264/  468] time: 202.9004, train_loss: 0.38510245, train_accuracy: 0.9062, test_Accuracy: 0.9436\n","Epoch: [ 0] [  265/  468] time: 203.5290, train_loss: 0.31285852, train_accuracy: 0.9531, test_Accuracy: 0.9443\n","Epoch: [ 0] [  266/  468] time: 204.1219, train_loss: 0.35698175, train_accuracy: 0.9141, test_Accuracy: 0.9450\n","Epoch: [ 0] [  267/  468] time: 204.7190, train_loss: 0.19006845, train_accuracy: 0.9766, test_Accuracy: 0.9462\n","Epoch: [ 0] [  268/  468] time: 206.1333, train_loss: 0.23546815, train_accuracy: 0.9453, test_Accuracy: 0.9470\n","Epoch: [ 0] [  269/  468] time: 207.5952, train_loss: 0.34056172, train_accuracy: 0.9531, test_Accuracy: 0.9463\n","Epoch: [ 0] [  270/  468] time: 208.2040, train_loss: 0.44023201, train_accuracy: 0.9453, test_Accuracy: 0.9459\n","Epoch: [ 0] [  271/  468] time: 208.7869, train_loss: 0.23019402, train_accuracy: 0.9531, test_Accuracy: 0.9463\n","Epoch: [ 0] [  272/  468] time: 209.3860, train_loss: 0.31374925, train_accuracy: 0.9766, test_Accuracy: 0.9457\n","Epoch: [ 0] [  273/  468] time: 210.0014, train_loss: 0.32615405, train_accuracy: 0.9375, test_Accuracy: 0.9461\n","Epoch: [ 0] [  274/  468] time: 210.7490, train_loss: 0.47051513, train_accuracy: 0.9141, test_Accuracy: 0.9457\n","Epoch: [ 0] [  275/  468] time: 211.3372, train_loss: 0.48098695, train_accuracy: 0.9141, test_Accuracy: 0.9467\n","Epoch: [ 0] [  276/  468] time: 211.9285, train_loss: 0.34504786, train_accuracy: 0.9609, test_Accuracy: 0.9474\n","Epoch: [ 0] [  277/  468] time: 212.5519, train_loss: 0.29853737, train_accuracy: 0.9375, test_Accuracy: 0.9480\n","Epoch: [ 0] [  278/  468] time: 213.1603, train_loss: 0.18382812, train_accuracy: 0.9844, test_Accuracy: 0.9474\n","Epoch: [ 0] [  279/  468] time: 213.7672, train_loss: 0.24520925, train_accuracy: 0.9531, test_Accuracy: 0.9462\n","Epoch: [ 0] [  280/  468] time: 214.3399, train_loss: 0.46421841, train_accuracy: 0.9141, test_Accuracy: 0.9447\n","Epoch: [ 0] [  281/  468] time: 214.9236, train_loss: 0.19885097, train_accuracy: 0.9609, test_Accuracy: 0.9435\n","Epoch: [ 0] [  282/  468] time: 215.5454, train_loss: 0.31021458, train_accuracy: 0.9141, test_Accuracy: 0.9438\n","Epoch: [ 0] [  283/  468] time: 216.1395, train_loss: 0.17022306, train_accuracy: 0.9688, test_Accuracy: 0.9446\n","Epoch: [ 0] [  284/  468] time: 216.7714, train_loss: 0.25316247, train_accuracy: 0.9531, test_Accuracy: 0.9456\n","Epoch: [ 0] [  285/  468] time: 217.5214, train_loss: 0.28662026, train_accuracy: 0.9531, test_Accuracy: 0.9448\n","Epoch: [ 0] [  286/  468] time: 218.9773, train_loss: 0.31350642, train_accuracy: 0.9609, test_Accuracy: 0.9457\n","Epoch: [ 0] [  287/  468] time: 219.8192, train_loss: 0.21103241, train_accuracy: 0.9453, test_Accuracy: 0.9458\n","Epoch: [ 0] [  288/  468] time: 220.5709, train_loss: 0.25633743, train_accuracy: 0.9531, test_Accuracy: 0.9456\n","Epoch: [ 0] [  289/  468] time: 221.1857, train_loss: 0.34347582, train_accuracy: 0.9453, test_Accuracy: 0.9463\n","Epoch: [ 0] [  290/  468] time: 221.7845, train_loss: 0.24859868, train_accuracy: 0.9531, test_Accuracy: 0.9464\n","Epoch: [ 0] [  291/  468] time: 222.3765, train_loss: 0.32646903, train_accuracy: 0.9453, test_Accuracy: 0.9466\n","Epoch: [ 0] [  292/  468] time: 223.0002, train_loss: 0.31686926, train_accuracy: 0.9531, test_Accuracy: 0.9464\n","Epoch: [ 0] [  293/  468] time: 223.5777, train_loss: 0.21844599, train_accuracy: 0.9766, test_Accuracy: 0.9468\n","Epoch: [ 0] [  294/  468] time: 224.1592, train_loss: 0.23370954, train_accuracy: 0.9297, test_Accuracy: 0.9464\n","Epoch: [ 0] [  295/  468] time: 224.8997, train_loss: 0.25844774, train_accuracy: 0.9531, test_Accuracy: 0.9455\n","Epoch: [ 0] [  296/  468] time: 225.6476, train_loss: 0.31511670, train_accuracy: 0.9453, test_Accuracy: 0.9457\n","Epoch: [ 0] [  297/  468] time: 226.2314, train_loss: 0.29024392, train_accuracy: 0.9609, test_Accuracy: 0.9450\n","Epoch: [ 0] [  298/  468] time: 226.9669, train_loss: 0.39571986, train_accuracy: 0.9531, test_Accuracy: 0.9441\n","Epoch: [ 0] [  299/  468] time: 227.5774, train_loss: 0.33999851, train_accuracy: 0.9375, test_Accuracy: 0.9433\n","Epoch: [ 0] [  300/  468] time: 228.1910, train_loss: 0.42475736, train_accuracy: 0.9219, test_Accuracy: 0.9438\n","Epoch: [ 0] [  301/  468] time: 228.7832, train_loss: 0.25988179, train_accuracy: 0.9609, test_Accuracy: 0.9451\n","Epoch: [ 0] [  302/  468] time: 229.5359, train_loss: 0.16884182, train_accuracy: 0.9766, test_Accuracy: 0.9446\n","Epoch: [ 0] [  303/  468] time: 230.9764, train_loss: 0.39204481, train_accuracy: 0.8828, test_Accuracy: 0.9475\n","Epoch: [ 0] [  304/  468] time: 231.9386, train_loss: 0.31802839, train_accuracy: 0.9531, test_Accuracy: 0.9470\n","Epoch: [ 0] [  305/  468] time: 232.5553, train_loss: 0.22994052, train_accuracy: 0.9922, test_Accuracy: 0.9470\n","Epoch: [ 0] [  306/  468] time: 233.1662, train_loss: 0.28059226, train_accuracy: 0.9297, test_Accuracy: 0.9477\n","Epoch: [ 0] [  307/  468] time: 233.7485, train_loss: 0.33919126, train_accuracy: 0.9688, test_Accuracy: 0.9486\n","Epoch: [ 0] [  308/  468] time: 234.3686, train_loss: 0.27387062, train_accuracy: 0.9609, test_Accuracy: 0.9490\n","Epoch: [ 0] [  309/  468] time: 234.9843, train_loss: 0.28240675, train_accuracy: 0.9531, test_Accuracy: 0.9496\n","Epoch: [ 0] [  310/  468] time: 235.5851, train_loss: 0.38274607, train_accuracy: 0.9297, test_Accuracy: 0.9510\n","Epoch: [ 0] [  311/  468] time: 236.2151, train_loss: 0.53013712, train_accuracy: 0.9141, test_Accuracy: 0.9508\n","Epoch: [ 0] [  312/  468] time: 236.8228, train_loss: 0.21017691, train_accuracy: 0.9609, test_Accuracy: 0.9499\n","Epoch: [ 0] [  313/  468] time: 237.4317, train_loss: 0.25423691, train_accuracy: 0.9688, test_Accuracy: 0.9496\n","Epoch: [ 0] [  314/  468] time: 238.1710, train_loss: 0.16738531, train_accuracy: 0.9844, test_Accuracy: 0.9478\n","Epoch: [ 0] [  315/  468] time: 238.7760, train_loss: 0.41047025, train_accuracy: 0.9297, test_Accuracy: 0.9472\n","Epoch: [ 0] [  316/  468] time: 239.3782, train_loss: 0.27180266, train_accuracy: 0.9219, test_Accuracy: 0.9472\n","Epoch: [ 0] [  317/  468] time: 239.9646, train_loss: 0.31357241, train_accuracy: 0.9375, test_Accuracy: 0.9465\n","Epoch: [ 0] [  318/  468] time: 240.5891, train_loss: 0.28694177, train_accuracy: 0.9375, test_Accuracy: 0.9465\n","Epoch: [ 0] [  319/  468] time: 241.1874, train_loss: 0.32430023, train_accuracy: 0.9531, test_Accuracy: 0.9472\n","Epoch: [ 0] [  320/  468] time: 241.7822, train_loss: 0.32456535, train_accuracy: 0.9453, test_Accuracy: 0.9480\n","Epoch: [ 0] [  321/  468] time: 243.1625, train_loss: 0.31814653, train_accuracy: 0.9297, test_Accuracy: 0.9492\n","Epoch: [ 0] [  322/  468] time: 244.6380, train_loss: 0.20384498, train_accuracy: 0.9688, test_Accuracy: 0.9500\n","Epoch: [ 0] [  323/  468] time: 245.3838, train_loss: 0.24944484, train_accuracy: 0.9766, test_Accuracy: 0.9496\n","Epoch: [ 0] [  324/  468] time: 245.9852, train_loss: 0.31396106, train_accuracy: 0.9219, test_Accuracy: 0.9497\n","Epoch: [ 0] [  325/  468] time: 246.5965, train_loss: 0.26712522, train_accuracy: 0.9688, test_Accuracy: 0.9502\n","Epoch: [ 0] [  326/  468] time: 247.3489, train_loss: 0.30928677, train_accuracy: 0.9922, test_Accuracy: 0.9490\n","Epoch: [ 0] [  327/  468] time: 247.9522, train_loss: 0.38015887, train_accuracy: 0.9453, test_Accuracy: 0.9483\n","Epoch: [ 0] [  328/  468] time: 248.5654, train_loss: 0.25280225, train_accuracy: 0.9453, test_Accuracy: 0.9477\n","Epoch: [ 0] [  329/  468] time: 249.1555, train_loss: 0.22670312, train_accuracy: 0.9609, test_Accuracy: 0.9470\n","Epoch: [ 0] [  330/  468] time: 249.7512, train_loss: 0.31814873, train_accuracy: 0.9531, test_Accuracy: 0.9452\n","Epoch: [ 0] [  331/  468] time: 250.3518, train_loss: 0.34752619, train_accuracy: 0.9375, test_Accuracy: 0.9457\n","Epoch: [ 0] [  332/  468] time: 250.9664, train_loss: 0.22855915, train_accuracy: 0.9766, test_Accuracy: 0.9459\n","Epoch: [ 0] [  333/  468] time: 251.7205, train_loss: 0.32193115, train_accuracy: 0.9375, test_Accuracy: 0.9445\n","Epoch: [ 0] [  334/  468] time: 252.3214, train_loss: 0.47323003, train_accuracy: 0.9375, test_Accuracy: 0.9442\n","Epoch: [ 0] [  335/  468] time: 252.9377, train_loss: 0.27294585, train_accuracy: 0.9531, test_Accuracy: 0.9443\n","Epoch: [ 0] [  336/  468] time: 253.5308, train_loss: 0.25764397, train_accuracy: 0.9531, test_Accuracy: 0.9443\n","Epoch: [ 0] [  337/  468] time: 254.2843, train_loss: 0.23631087, train_accuracy: 0.9531, test_Accuracy: 0.9456\n","Epoch: [ 0] [  338/  468] time: 255.7326, train_loss: 0.17852500, train_accuracy: 0.9766, test_Accuracy: 0.9473\n","Epoch: [ 0] [  339/  468] time: 256.7279, train_loss: 0.28383872, train_accuracy: 0.9531, test_Accuracy: 0.9485\n","Epoch: [ 0] [  340/  468] time: 257.3472, train_loss: 0.24258508, train_accuracy: 0.9531, test_Accuracy: 0.9502\n","Epoch: [ 0] [  341/  468] time: 257.9325, train_loss: 0.24918535, train_accuracy: 0.9531, test_Accuracy: 0.9494\n","Epoch: [ 0] [  342/  468] time: 258.6739, train_loss: 0.31375834, train_accuracy: 0.9453, test_Accuracy: 0.9475\n","Epoch: [ 0] [  343/  468] time: 259.2931, train_loss: 0.26393527, train_accuracy: 0.9688, test_Accuracy: 0.9469\n","Epoch: [ 0] [  344/  468] time: 259.8869, train_loss: 0.21710417, train_accuracy: 0.9375, test_Accuracy: 0.9452\n","Epoch: [ 0] [  345/  468] time: 260.4842, train_loss: 0.12839033, train_accuracy: 0.9766, test_Accuracy: 0.9443\n","Epoch: [ 0] [  346/  468] time: 261.1136, train_loss: 0.28762335, train_accuracy: 0.9531, test_Accuracy: 0.9450\n","Epoch: [ 0] [  347/  468] time: 261.6835, train_loss: 0.38860303, train_accuracy: 0.9375, test_Accuracy: 0.9462\n","Epoch: [ 0] [  348/  468] time: 262.2585, train_loss: 0.27859008, train_accuracy: 0.9453, test_Accuracy: 0.9469\n","Epoch: [ 0] [  349/  468] time: 262.8458, train_loss: 0.12249290, train_accuracy: 0.9922, test_Accuracy: 0.9475\n","Epoch: [ 0] [  350/  468] time: 263.4451, train_loss: 0.42767376, train_accuracy: 0.9141, test_Accuracy: 0.9496\n","Epoch: [ 0] [  351/  468] time: 264.0690, train_loss: 0.22723657, train_accuracy: 0.9375, test_Accuracy: 0.9496\n","Epoch: [ 0] [  352/  468] time: 264.6711, train_loss: 0.15301678, train_accuracy: 0.9531, test_Accuracy: 0.9480\n","Epoch: [ 0] [  353/  468] time: 265.3080, train_loss: 0.23480472, train_accuracy: 0.9453, test_Accuracy: 0.9467\n","Epoch: [ 0] [  354/  468] time: 266.0508, train_loss: 0.26406568, train_accuracy: 0.9531, test_Accuracy: 0.9450\n","Epoch: [ 0] [  355/  468] time: 266.7952, train_loss: 0.38796049, train_accuracy: 0.9375, test_Accuracy: 0.9450\n","Epoch: [ 0] [  356/  468] time: 267.8005, train_loss: 0.20481610, train_accuracy: 0.9609, test_Accuracy: 0.9450\n","Epoch: [ 0] [  357/  468] time: 269.2475, train_loss: 0.30661106, train_accuracy: 0.9375, test_Accuracy: 0.9444\n","Epoch: [ 0] [  358/  468] time: 269.8414, train_loss: 0.37292573, train_accuracy: 0.9219, test_Accuracy: 0.9447\n","Epoch: [ 0] [  359/  468] time: 270.4547, train_loss: 0.30804199, train_accuracy: 0.9688, test_Accuracy: 0.9458\n","Epoch: [ 0] [  360/  468] time: 271.0367, train_loss: 0.31598300, train_accuracy: 0.9375, test_Accuracy: 0.9469\n","Epoch: [ 0] [  361/  468] time: 271.7876, train_loss: 0.44205654, train_accuracy: 0.9062, test_Accuracy: 0.9480\n","Epoch: [ 0] [  362/  468] time: 272.5328, train_loss: 0.23953047, train_accuracy: 0.9609, test_Accuracy: 0.9486\n","Epoch: [ 0] [  363/  468] time: 273.1348, train_loss: 0.42533448, train_accuracy: 0.9297, test_Accuracy: 0.9498\n","Epoch: [ 0] [  364/  468] time: 273.7327, train_loss: 0.24630901, train_accuracy: 0.9531, test_Accuracy: 0.9505\n","Epoch: [ 0] [  365/  468] time: 274.3087, train_loss: 0.27850032, train_accuracy: 0.8906, test_Accuracy: 0.9520\n","Epoch: [ 0] [  366/  468] time: 274.8947, train_loss: 0.30169261, train_accuracy: 0.9688, test_Accuracy: 0.9508\n","Epoch: [ 0] [  367/  468] time: 275.4879, train_loss: 0.21026890, train_accuracy: 0.9844, test_Accuracy: 0.9496\n","Epoch: [ 0] [  368/  468] time: 276.0837, train_loss: 0.30038470, train_accuracy: 0.9453, test_Accuracy: 0.9501\n","Epoch: [ 0] [  369/  468] time: 276.6687, train_loss: 0.20942132, train_accuracy: 0.9531, test_Accuracy: 0.9505\n","Epoch: [ 0] [  370/  468] time: 277.2830, train_loss: 0.25353166, train_accuracy: 0.9531, test_Accuracy: 0.9497\n","Epoch: [ 0] [  371/  468] time: 277.8711, train_loss: 0.23054144, train_accuracy: 0.9297, test_Accuracy: 0.9503\n","Epoch: [ 0] [  372/  468] time: 278.4559, train_loss: 0.27552775, train_accuracy: 0.9609, test_Accuracy: 0.9512\n","Epoch: [ 0] [  373/  468] time: 279.0925, train_loss: 0.14725794, train_accuracy: 0.9688, test_Accuracy: 0.9511\n","Epoch: [ 0] [  374/  468] time: 280.5139, train_loss: 0.24201290, train_accuracy: 0.9609, test_Accuracy: 0.9520\n","Epoch: [ 0] [  375/  468] time: 281.4828, train_loss: 0.39167175, train_accuracy: 0.9375, test_Accuracy: 0.9519\n","Epoch: [ 0] [  376/  468] time: 282.2653, train_loss: 0.18675315, train_accuracy: 0.9688, test_Accuracy: 0.9520\n","Epoch: [ 0] [  377/  468] time: 282.8607, train_loss: 0.33712220, train_accuracy: 0.9609, test_Accuracy: 0.9532\n","Epoch: [ 0] [  378/  468] time: 283.4431, train_loss: 0.15505165, train_accuracy: 0.9688, test_Accuracy: 0.9525\n","Epoch: [ 0] [  379/  468] time: 284.1975, train_loss: 0.28186622, train_accuracy: 0.9453, test_Accuracy: 0.9520\n","Epoch: [ 0] [  380/  468] time: 284.7914, train_loss: 0.16479123, train_accuracy: 0.9531, test_Accuracy: 0.9522\n","Epoch: [ 0] [  381/  468] time: 285.3677, train_loss: 0.22230758, train_accuracy: 0.9609, test_Accuracy: 0.9523\n","Epoch: [ 0] [  382/  468] time: 285.9595, train_loss: 0.36952344, train_accuracy: 0.9531, test_Accuracy: 0.9524\n","Epoch: [ 0] [  383/  468] time: 286.5540, train_loss: 0.29865336, train_accuracy: 0.9375, test_Accuracy: 0.9527\n","Epoch: [ 0] [  384/  468] time: 287.1524, train_loss: 0.20020539, train_accuracy: 0.9844, test_Accuracy: 0.9520\n","Epoch: [ 0] [  385/  468] time: 287.9006, train_loss: 0.34272534, train_accuracy: 0.9375, test_Accuracy: 0.9518\n","Epoch: [ 0] [  386/  468] time: 288.5089, train_loss: 0.37242430, train_accuracy: 0.9141, test_Accuracy: 0.9513\n","Epoch: [ 0] [  387/  468] time: 289.1090, train_loss: 0.25859606, train_accuracy: 0.9609, test_Accuracy: 0.9509\n","Epoch: [ 0] [  388/  468] time: 289.7270, train_loss: 0.22017688, train_accuracy: 0.9297, test_Accuracy: 0.9509\n","Epoch: [ 0] [  389/  468] time: 290.3218, train_loss: 0.36591530, train_accuracy: 0.9141, test_Accuracy: 0.9510\n","Epoch: [ 0] [  390/  468] time: 290.9064, train_loss: 0.22638857, train_accuracy: 0.9688, test_Accuracy: 0.9509\n","Epoch: [ 0] [  391/  468] time: 291.4936, train_loss: 0.34166312, train_accuracy: 0.9453, test_Accuracy: 0.9493\n","Epoch: [ 0] [  392/  468] time: 292.8913, train_loss: 0.23506387, train_accuracy: 0.9531, test_Accuracy: 0.9494\n","Epoch: [ 0] [  393/  468] time: 293.8907, train_loss: 0.28232062, train_accuracy: 0.9844, test_Accuracy: 0.9498\n","Epoch: [ 0] [  394/  468] time: 294.5186, train_loss: 0.31306887, train_accuracy: 0.9375, test_Accuracy: 0.9502\n","Epoch: [ 0] [  395/  468] time: 295.1371, train_loss: 0.20440996, train_accuracy: 0.9609, test_Accuracy: 0.9506\n","Epoch: [ 0] [  396/  468] time: 295.7337, train_loss: 0.25785536, train_accuracy: 0.9609, test_Accuracy: 0.9520\n","Epoch: [ 0] [  397/  468] time: 296.3321, train_loss: 0.19417813, train_accuracy: 0.9531, test_Accuracy: 0.9527\n","Epoch: [ 0] [  398/  468] time: 296.9442, train_loss: 0.48563820, train_accuracy: 0.9375, test_Accuracy: 0.9513\n","Epoch: [ 0] [  399/  468] time: 297.5361, train_loss: 0.36429775, train_accuracy: 0.8984, test_Accuracy: 0.9513\n","Epoch: [ 0] [  400/  468] time: 298.1508, train_loss: 0.26803896, train_accuracy: 0.9297, test_Accuracy: 0.9486\n","Epoch: [ 0] [  401/  468] time: 298.7442, train_loss: 0.20053887, train_accuracy: 0.9766, test_Accuracy: 0.9454\n","Epoch: [ 0] [  402/  468] time: 299.3563, train_loss: 0.37792525, train_accuracy: 0.9141, test_Accuracy: 0.9451\n","Epoch: [ 0] [  403/  468] time: 299.9752, train_loss: 0.25180838, train_accuracy: 0.9609, test_Accuracy: 0.9451\n","Epoch: [ 0] [  404/  468] time: 300.7227, train_loss: 0.29398113, train_accuracy: 0.9531, test_Accuracy: 0.9457\n","Epoch: [ 0] [  405/  468] time: 301.4620, train_loss: 0.25884432, train_accuracy: 0.9453, test_Accuracy: 0.9462\n","Epoch: [ 0] [  406/  468] time: 302.0599, train_loss: 0.18554053, train_accuracy: 0.9531, test_Accuracy: 0.9475\n","Epoch: [ 0] [  407/  468] time: 302.6429, train_loss: 0.33148837, train_accuracy: 0.9453, test_Accuracy: 0.9476\n","Epoch: [ 0] [  408/  468] time: 303.2486, train_loss: 0.25308400, train_accuracy: 0.9531, test_Accuracy: 0.9499\n","Epoch: [ 0] [  409/  468] time: 303.8331, train_loss: 0.25084922, train_accuracy: 0.9375, test_Accuracy: 0.9513\n","Epoch: [ 0] [  410/  468] time: 305.2116, train_loss: 0.33924592, train_accuracy: 0.9219, test_Accuracy: 0.9521\n","Epoch: [ 0] [  411/  468] time: 306.6553, train_loss: 0.24206136, train_accuracy: 0.9844, test_Accuracy: 0.9509\n","Epoch: [ 0] [  412/  468] time: 307.2669, train_loss: 0.30945569, train_accuracy: 0.9688, test_Accuracy: 0.9499\n","Epoch: [ 0] [  413/  468] time: 307.8468, train_loss: 0.30622831, train_accuracy: 0.9688, test_Accuracy: 0.9501\n","Epoch: [ 0] [  414/  468] time: 308.5864, train_loss: 0.24579228, train_accuracy: 0.9531, test_Accuracy: 0.9501\n","Epoch: [ 0] [  415/  468] time: 309.3435, train_loss: 0.20654953, train_accuracy: 0.9609, test_Accuracy: 0.9503\n","Epoch: [ 0] [  416/  468] time: 309.9393, train_loss: 0.21760392, train_accuracy: 0.9609, test_Accuracy: 0.9516\n","Epoch: [ 0] [  417/  468] time: 310.5514, train_loss: 0.14442289, train_accuracy: 0.9766, test_Accuracy: 0.9536\n","Epoch: [ 0] [  418/  468] time: 311.1203, train_loss: 0.21877810, train_accuracy: 0.9531, test_Accuracy: 0.9549\n","Epoch: [ 0] [  419/  468] time: 311.6928, train_loss: 0.28957233, train_accuracy: 0.9375, test_Accuracy: 0.9543\n","Epoch: [ 0] [  420/  468] time: 312.3162, train_loss: 0.26410452, train_accuracy: 0.9297, test_Accuracy: 0.9524\n","Epoch: [ 0] [  421/  468] time: 312.9351, train_loss: 0.12325276, train_accuracy: 0.9844, test_Accuracy: 0.9512\n","Epoch: [ 0] [  422/  468] time: 313.5544, train_loss: 0.21727528, train_accuracy: 0.9531, test_Accuracy: 0.9510\n","Epoch: [ 0] [  423/  468] time: 314.1479, train_loss: 0.19088852, train_accuracy: 0.9766, test_Accuracy: 0.9513\n","Epoch: [ 0] [  424/  468] time: 314.8994, train_loss: 0.38143188, train_accuracy: 0.9297, test_Accuracy: 0.9516\n","Epoch: [ 0] [  425/  468] time: 315.4806, train_loss: 0.27558839, train_accuracy: 0.9375, test_Accuracy: 0.9520\n","Epoch: [ 0] [  426/  468] time: 316.0914, train_loss: 0.28885537, train_accuracy: 0.9531, test_Accuracy: 0.9527\n","Epoch: [ 0] [  427/  468] time: 316.8408, train_loss: 0.42695105, train_accuracy: 0.9141, test_Accuracy: 0.9544\n","Epoch: [ 0] [  428/  468] time: 317.8455, train_loss: 0.20483461, train_accuracy: 0.9609, test_Accuracy: 0.9558\n","Epoch: [ 0] [  429/  468] time: 319.2791, train_loss: 0.29298708, train_accuracy: 0.9453, test_Accuracy: 0.9560\n","Epoch: [ 0] [  430/  468] time: 319.8735, train_loss: 0.16561618, train_accuracy: 0.9609, test_Accuracy: 0.9559\n","Epoch: [ 0] [  431/  468] time: 320.4801, train_loss: 0.10749815, train_accuracy: 0.9844, test_Accuracy: 0.9565\n","Epoch: [ 0] [  432/  468] time: 321.0893, train_loss: 0.17747003, train_accuracy: 0.9688, test_Accuracy: 0.9552\n","Epoch: [ 0] [  433/  468] time: 321.8282, train_loss: 0.27848220, train_accuracy: 0.9766, test_Accuracy: 0.9545\n","Epoch: [ 0] [  434/  468] time: 322.4185, train_loss: 0.49456236, train_accuracy: 0.9375, test_Accuracy: 0.9542\n","Epoch: [ 0] [  435/  468] time: 323.0287, train_loss: 0.21952960, train_accuracy: 0.9453, test_Accuracy: 0.9538\n","Epoch: [ 0] [  436/  468] time: 323.6095, train_loss: 0.20282090, train_accuracy: 0.9453, test_Accuracy: 0.9544\n","Epoch: [ 0] [  437/  468] time: 324.2105, train_loss: 0.22406611, train_accuracy: 0.9453, test_Accuracy: 0.9553\n","Epoch: [ 0] [  438/  468] time: 324.9520, train_loss: 0.29069722, train_accuracy: 0.9453, test_Accuracy: 0.9557\n","Epoch: [ 0] [  439/  468] time: 325.5514, train_loss: 0.19960541, train_accuracy: 0.9688, test_Accuracy: 0.9562\n","Epoch: [ 0] [  440/  468] time: 326.1334, train_loss: 0.22206977, train_accuracy: 0.9609, test_Accuracy: 0.9564\n","Epoch: [ 0] [  441/  468] time: 326.7178, train_loss: 0.19811971, train_accuracy: 0.9688, test_Accuracy: 0.9567\n","Epoch: [ 0] [  442/  468] time: 327.3339, train_loss: 0.16391642, train_accuracy: 0.9844, test_Accuracy: 0.9564\n","Epoch: [ 0] [  443/  468] time: 327.9388, train_loss: 0.21790832, train_accuracy: 0.9609, test_Accuracy: 0.9554\n","Epoch: [ 0] [  444/  468] time: 328.5158, train_loss: 0.34158802, train_accuracy: 0.9453, test_Accuracy: 0.9546\n","Epoch: [ 0] [  445/  468] time: 329.1330, train_loss: 0.27168426, train_accuracy: 0.9453, test_Accuracy: 0.9545\n","Epoch: [ 0] [  446/  468] time: 330.5788, train_loss: 0.28454107, train_accuracy: 0.9531, test_Accuracy: 0.9535\n","Epoch: [ 0] [  447/  468] time: 331.5030, train_loss: 0.39015743, train_accuracy: 0.9297, test_Accuracy: 0.9538\n","Epoch: [ 0] [  448/  468] time: 332.1279, train_loss: 0.19665472, train_accuracy: 0.9766, test_Accuracy: 0.9543\n","Epoch: [ 0] [  449/  468] time: 332.8701, train_loss: 0.18476896, train_accuracy: 0.9688, test_Accuracy: 0.9552\n","Epoch: [ 0] [  450/  468] time: 333.4511, train_loss: 0.29761177, train_accuracy: 0.9766, test_Accuracy: 0.9556\n","Epoch: [ 0] [  451/  468] time: 334.0221, train_loss: 0.18901631, train_accuracy: 0.9688, test_Accuracy: 0.9560\n","Epoch: [ 0] [  452/  468] time: 334.6419, train_loss: 0.22594571, train_accuracy: 0.9688, test_Accuracy: 0.9558\n","Epoch: [ 0] [  453/  468] time: 335.2545, train_loss: 0.14229384, train_accuracy: 0.9766, test_Accuracy: 0.9553\n","Epoch: [ 0] [  454/  468] time: 335.8600, train_loss: 0.22892055, train_accuracy: 0.9609, test_Accuracy: 0.9539\n","Epoch: [ 0] [  455/  468] time: 336.4688, train_loss: 0.23592263, train_accuracy: 0.9297, test_Accuracy: 0.9522\n","Epoch: [ 0] [  456/  468] time: 337.0623, train_loss: 0.33277336, train_accuracy: 0.9688, test_Accuracy: 0.9520\n","Epoch: [ 0] [  457/  468] time: 337.6546, train_loss: 0.26733661, train_accuracy: 0.9688, test_Accuracy: 0.9517\n","Epoch: [ 0] [  458/  468] time: 338.2735, train_loss: 0.33365709, train_accuracy: 0.9531, test_Accuracy: 0.9517\n","Epoch: [ 0] [  459/  468] time: 338.8515, train_loss: 0.31426057, train_accuracy: 0.9141, test_Accuracy: 0.9526\n","Epoch: [ 0] [  460/  468] time: 339.4588, train_loss: 0.23367938, train_accuracy: 0.9609, test_Accuracy: 0.9538\n","Epoch: [ 0] [  461/  468] time: 340.2029, train_loss: 0.19791213, train_accuracy: 0.9766, test_Accuracy: 0.9545\n","Epoch: [ 0] [  462/  468] time: 340.8154, train_loss: 0.28211597, train_accuracy: 0.9531, test_Accuracy: 0.9529\n","Epoch: [ 0] [  463/  468] time: 341.4216, train_loss: 0.29122332, train_accuracy: 0.9297, test_Accuracy: 0.9518\n","Epoch: [ 0] [  464/  468] time: 342.8395, train_loss: 0.22295558, train_accuracy: 0.9609, test_Accuracy: 0.9523\n","Epoch: [ 0] [  465/  468] time: 344.2919, train_loss: 0.26952344, train_accuracy: 0.9297, test_Accuracy: 0.9517\n","Epoch: [ 0] [  466/  468] time: 344.8922, train_loss: 0.21013072, train_accuracy: 0.9609, test_Accuracy: 0.9518\n","Epoch: [ 0] [  467/  468] time: 345.4900, train_loss: 0.24044345, train_accuracy: 0.9609, test_Accuracy: 0.9538\n"]}]},{"cell_type":"markdown","source":["**Softmax test_Accuracy: 0.9237**\n","\n","**Relu test_Accuracy: 0.9584**\n","\n","**Relu + Xavier Initialization test_Accuracy: 0.9643**\n","\n","**Relu + Xavier + Dense 512 test_Accuracy: 0.9663**\n","\n","**Relu + Xavier + Dense 512 + Dropout test_Accuracy: 0.9538**"],"metadata":{"id":"FaiXdBO8FxQg"}},{"cell_type":"code","source":[],"metadata":{"id":"AkYxwqiDFwLX"},"execution_count":null,"outputs":[]}]}